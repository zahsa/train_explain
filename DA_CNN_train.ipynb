{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "DACCO_CNN3.ipynb",
   "provenance": [
    {
     "file_id": "18wt9237MVqRxD08_vkdmMyCgYCraalov",
     "timestamp": 1600420039440
    }
   ],
   "collapsed_sections": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "8e08yST59Ht8"
   },
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7_ld64CfZIKf"
   },
   "source": [
    "import warnings\n",
    "# Ingnore warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas.util.testing as tm\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import os\n",
    "import random\n",
    "import math"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4ElGGpWfZtR3"
   },
   "source": [
    "# Load datasets\n",
    "data_folder = \"./DA\"\n",
    "\n",
    "df_test_X = pd.read_csv(os.path.join(data_folder, \"Test1.csv\"))\n",
    "df_test_Y = pd.read_csv(os.path.join(data_folder,\"Test2.csv\"))\n",
    "df_train_X = pd.read_csv(os.path.join(data_folder,\"Train1.csv\"))\n",
    "df_train_Y = pd.read_csv(os.path.join(data_folder, \"Train2.csv\"))\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KZAWSfstPkG8"
   },
   "source": [
    "test_X = df_test_X[df_test_X.columns[1:]]\n",
    "train_X = df_train_X[df_train_X.columns[1:]]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "n56kliXqIqow"
   },
   "source": [
    "x_test = test_X.to_numpy()\n",
    "x_train = train_X.to_numpy()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zZH0KTntK-Cm"
   },
   "source": [
    "y_test = test_Y.to_numpy()\n",
    "y_train = train_Y.to_numpy()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "p2DW7-t7EtWJ"
   },
   "source": [
    "\n",
    "# dates = []\n",
    "# scores = []\n",
    "\n",
    "# with open('file.csv') as csvDataFile:\n",
    "#     csvReader = csv.reader(csvDataFile)\n",
    "#     for row in csvReader:\n",
    "#         dates.append(row[0])\n",
    "#         scores.append(row[1])\n",
    "\n",
    "# print(dates)\n",
    "# print(scores)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DiJxhMikJ2RQ"
   },
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras import regularizers\n",
    "max_features = 3 # 27205\n",
    "max_len = 27205# 800"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "N2djtxLZt-OM"
   },
   "source": [
    "BatchSize= 64 \n",
    "ParamsLambdaRegularization = 2.5\n",
    "HyperparametersEmbeddingDimension = 10\n",
    "ParamsConvolutionNumber = 2 \n",
    "ParamsConvolutionShape = \"conic\"\n",
    "ParamsDenseShape = \"conic\"\n",
    "ParamsFilterNumber = 64\n",
    "Type = \"CNN\"\n",
    "ParamsDenseNumber = 1\n",
    "ParamsUnitNumber = 64\n",
    "ParamsDropRate = 0.4\n",
    "LearningRate = 0.0001\n",
    "ParamsKernelSize = 9\n",
    "Denominator = 800/BatchSize\n",
    "LambdaRegularization = ParamsLambdaRegularization/Denominator\n",
    "embedding_dim = 10\n",
    "PoolStride= 5"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "AVjsGWghDOuc"
   },
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sxmfWhgpJ2ND",
    "executionInfo": {
     "elapsed": 244,
     "status": "ok",
     "timestamp": 1626367128975,
     "user": {
      "displayName": "Zahra Sadeghi",
      "photoUrl": "",
      "userId": "17928363754993821426"
     },
     "user_tz": -120
    },
    "outputId": "0d52d8cd-9fcd-45c9-b204-fbd0f46e3d61"
   },
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras import layers, activations\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(max_features, embedding_dim, input_length=max_len , embeddings_initializer=\"LecunNormal\"))\n",
    "\n",
    "if (ParamsConvolutionNumber > 0):\n",
    "    for i in range(1,ParamsConvolutionNumber+1):\n",
    "        print('i {}'.format(i))\n",
    "        if ParamsConvolutionShape == \"conic\":\n",
    "            FilterNumberL = ParamsFilterNumber*2**(i-1)\n",
    "        elif (ParamsConvolutionShape == \"rectangular\"):\n",
    "            FilterNumberL = ParamsFilterNumber\n",
    "\n",
    "        if Type == \"CNN\":\n",
    "            model.add(layers.Conv1D(filters = FilterNumberL, kernel_size = ParamsKernelSize, kernel_regularizer = regularizers.l2(LambdaRegularization),activation='relu'))\n",
    "            checkpoint_filepath = os.path.join(data_folder,'best_cnn_model_test_val.hdf5')\n",
    "\n",
    "        elif Type == \"SNN\":\n",
    "            model.add(layers.Conv1D(filters = FilterNumberL, kernel_size = ParamsKernelSize, kernel_initializer = \"LecunNormal\",activation='selu'))\n",
    "            checkpoint_filepath = os.path.join(data_folder,'best_snn_model.hdf5')\n",
    "\n",
    "\n",
    "        model.add(layers.MaxPooling1D(pool_size = PoolStride))\n",
    "\n",
    "     \n",
    "\n",
    "model.add(layers.Flatten())           \n",
    "\n",
    "if (ParamsDenseNumber > 0):\n",
    "    for j in range(1,ParamsDenseNumber+1):\n",
    "        if ParamsDenseShape == \"conic\":\n",
    "            UnitNumberL = math.floor(ParamsUnitNumber*2**(j-1))\n",
    "        elif ParamsDenseShape == \"rectangular\":\n",
    "            UnitNumberL = ParamsUnitNumber\n",
    "\n",
    "\n",
    "        if (Type == \"CNN\"):\n",
    "            model.add(Dropout(ParamsDropRate))\n",
    "            model.add(layers.Dense(units = UnitNumberL, kernel_regularizer=regularizers.l2(LambdaRegularization),activation='relu'))\n",
    "            \n",
    "        elif Type == \"SNN\":\n",
    "            model.add(Dropout(ParamsDropRate))\n",
    "            model.add(layers.Dense(units = UnitNumberL, kernel_regularizer=regularizers.l2(LambdaRegularization),activation='selu'))\n",
    "           \n",
    "\n",
    "\n",
    "if (Type == \"CNN\"):\n",
    "    model.add(Dropout(ParamsDropRate))\n",
    "\n",
    "elif(Type == \"SNN\"):\n",
    "    model.add(AlphaDropout(ParamsDropRate))\n",
    "\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "\n",
    "\n",
    "model.summary()\n"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "i 1\n",
      "i 2\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 27205, 10)         30        \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 27197, 64)         5824      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 5439, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 5431, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 1086, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 139008)            0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 139008)            0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                8896576   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 8,976,351\n",
      "Trainable params: 8,976,351\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XKmrwUIQNKwL"
   },
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eRmSZp2XPAaT"
   },
   "source": [
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath, \n",
    "                             monitor='val_loss',\n",
    "                             verbose=1, \n",
    "                             save_best_only=True,\n",
    "                             mode='min')\n",
    "model_checkpoint_callback = [checkpoint]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "IR5m8VEnBkxJ",
    "outputId": "e5ddb5a3-a665-4ef3-ccbe-1641a7b7a173"
   },
   "source": [
    "opt = keras.optimizers.Adam(learning_rate = 1e-4)\n",
    "model.compile(optimizer = opt,\n",
    "              loss='mse',\n",
    "              metrics=['mean_absolute_error'])\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
    "history = model.fit(train_X, train_Y,\n",
    "                    epochs=1000,\n",
    "                    batch_size=64,\n",
    "                    # validation_split=0.2,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=model_checkpoint_callback  \n",
    "                    )"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "13/13 [==============================] - 77s 5s/step - loss: 1837.5101 - mean_absolute_error: 33.8694 - val_loss: 901.2878 - val_mean_absolute_error: 25.6308\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 901.28784, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model_test_val.hdf5\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 58s 4s/step - loss: 928.0071 - mean_absolute_error: 25.7506 - val_loss: 770.2194 - val_mean_absolute_error: 23.5358\n",
      "\n",
      "Epoch 00002: val_loss improved from 901.28784 to 770.21936, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model_test_val.hdf5\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 59s 4s/step - loss: 798.2887 - mean_absolute_error: 23.5820 - val_loss: 634.7170 - val_mean_absolute_error: 20.6319\n",
      "\n",
      "Epoch 00003: val_loss improved from 770.21936 to 634.71704, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model_test_val.hdf5\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 58s 4s/step - loss: 628.8674 - mean_absolute_error: 20.2764 - val_loss: 507.1332 - val_mean_absolute_error: 17.7028\n",
      "\n",
      "Epoch 00004: val_loss improved from 634.71704 to 507.13321, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model_test_val.hdf5\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 504.6526 - mean_absolute_error: 17.3649 - val_loss: 433.1090 - val_mean_absolute_error: 16.0098\n",
      "\n",
      "Epoch 00005: val_loss improved from 507.13321 to 433.10898, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model_test_val.hdf5\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 428.7648 - mean_absolute_error: 15.7910 - val_loss: 372.8419 - val_mean_absolute_error: 13.8981\n",
      "\n",
      "Epoch 00006: val_loss improved from 433.10898 to 372.84192, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model_test_val.hdf5\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 339.2839 - mean_absolute_error: 13.7162 - val_loss: 346.6353 - val_mean_absolute_error: 13.1719\n",
      "\n",
      "Epoch 00007: val_loss improved from 372.84192 to 346.63535, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model_test_val.hdf5\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 323.9173 - mean_absolute_error: 13.2610 - val_loss: 328.1405 - val_mean_absolute_error: 12.4857\n",
      "\n",
      "Epoch 00008: val_loss improved from 346.63535 to 328.14047, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model_test_val.hdf5\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 292.1434 - mean_absolute_error: 12.5015 - val_loss: 306.8584 - val_mean_absolute_error: 11.9032\n",
      "\n",
      "Epoch 00009: val_loss improved from 328.14047 to 306.85843, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model_test_val.hdf5\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 280.0488 - mean_absolute_error: 12.1898 - val_loss: 295.2575 - val_mean_absolute_error: 11.6195\n",
      "\n",
      "Epoch 00010: val_loss improved from 306.85843 to 295.25748, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model_test_val.hdf5\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 238.9290 - mean_absolute_error: 11.0740 - val_loss: 287.1778 - val_mean_absolute_error: 11.5357\n",
      "\n",
      "Epoch 00011: val_loss improved from 295.25748 to 287.17783, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model_test_val.hdf5\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 242.2694 - mean_absolute_error: 11.3403 - val_loss: 291.5661 - val_mean_absolute_error: 11.9462\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 287.17783\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 243.2058 - mean_absolute_error: 11.0975 - val_loss: 290.8442 - val_mean_absolute_error: 11.8776\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 287.17783\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 216.3893 - mean_absolute_error: 10.5121 - val_loss: 281.2882 - val_mean_absolute_error: 11.4977\n",
      "\n",
      "Epoch 00014: val_loss improved from 287.17783 to 281.28824, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model_test_val.hdf5\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 240.4632 - mean_absolute_error: 11.1218 - val_loss: 278.5904 - val_mean_absolute_error: 11.5249\n",
      "\n",
      "Epoch 00015: val_loss improved from 281.28824 to 278.59036, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model_test_val.hdf5\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 222.2216 - mean_absolute_error: 10.2079 - val_loss: 272.6287 - val_mean_absolute_error: 11.4296\n",
      "\n",
      "Epoch 00016: val_loss improved from 278.59036 to 272.62866, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model_test_val.hdf5\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 221.2399 - mean_absolute_error: 10.7929 - val_loss: 270.9460 - val_mean_absolute_error: 11.3886\n",
      "\n",
      "Epoch 00017: val_loss improved from 272.62866 to 270.94598, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model_test_val.hdf5\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 232.6294 - mean_absolute_error: 10.8058 - val_loss: 259.4959 - val_mean_absolute_error: 11.1406\n",
      "\n",
      "Epoch 00018: val_loss improved from 270.94598 to 259.49591, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model_test_val.hdf5\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 217.0790 - mean_absolute_error: 10.3146 - val_loss: 263.1932 - val_mean_absolute_error: 11.1522\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 259.49591\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 194.7515 - mean_absolute_error: 9.8348 - val_loss: 257.7363 - val_mean_absolute_error: 11.2640\n",
      "\n",
      "Epoch 00020: val_loss improved from 259.49591 to 257.73630, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model_test_val.hdf5\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 209.0926 - mean_absolute_error: 10.0782 - val_loss: 250.6877 - val_mean_absolute_error: 10.9808\n",
      "\n",
      "Epoch 00021: val_loss improved from 257.73630 to 250.68773, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model_test_val.hdf5\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 210.6141 - mean_absolute_error: 10.4173 - val_loss: 248.8049 - val_mean_absolute_error: 10.9066\n",
      "\n",
      "Epoch 00022: val_loss improved from 250.68773 to 248.80487, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model_test_val.hdf5\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 193.8694 - mean_absolute_error: 9.7683 - val_loss: 246.0984 - val_mean_absolute_error: 10.9487\n",
      "\n",
      "Epoch 00023: val_loss improved from 248.80487 to 246.09843, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model_test_val.hdf5\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 209.9281 - mean_absolute_error: 10.2018 - val_loss: 248.7589 - val_mean_absolute_error: 11.0500\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 246.09843\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 200.7249 - mean_absolute_error: 10.0440 - val_loss: 246.0903 - val_mean_absolute_error: 11.0693\n",
      "\n",
      "Epoch 00025: val_loss improved from 246.09843 to 246.09029, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model_test_val.hdf5\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 183.5754 - mean_absolute_error: 9.6994 - val_loss: 238.1741 - val_mean_absolute_error: 10.7748\n",
      "\n",
      "Epoch 00026: val_loss improved from 246.09029 to 238.17410, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model_test_val.hdf5\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 197.6333 - mean_absolute_error: 9.9478 - val_loss: 248.6414 - val_mean_absolute_error: 10.9728\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 238.17410\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 222.1748 - mean_absolute_error: 10.5034 - val_loss: 237.4343 - val_mean_absolute_error: 10.7957\n",
      "\n",
      "Epoch 00028: val_loss improved from 238.17410 to 237.43434, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model_test_val.hdf5\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 180.7576 - mean_absolute_error: 9.7279 - val_loss: 232.3578 - val_mean_absolute_error: 10.6834\n",
      "\n",
      "Epoch 00029: val_loss improved from 237.43434 to 232.35777, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model_test_val.hdf5\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 207.6035 - mean_absolute_error: 10.0076 - val_loss: 230.4085 - val_mean_absolute_error: 10.7431\n",
      "\n",
      "Epoch 00030: val_loss improved from 232.35777 to 230.40851, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model_test_val.hdf5\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 192.9921 - mean_absolute_error: 9.9339 - val_loss: 231.6564 - val_mean_absolute_error: 10.8151\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 230.40851\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 196.1261 - mean_absolute_error: 9.6379 - val_loss: 223.3156 - val_mean_absolute_error: 10.5403\n",
      "\n",
      "Epoch 00032: val_loss improved from 230.40851 to 223.31564, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model_test_val.hdf5\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 183.0961 - mean_absolute_error: 9.4370 - val_loss: 223.3467 - val_mean_absolute_error: 10.5821\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 223.31564\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 170.7701 - mean_absolute_error: 9.1767 - val_loss: 221.9570 - val_mean_absolute_error: 10.5704\n",
      "\n",
      "Epoch 00034: val_loss improved from 223.31564 to 221.95703, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model_test_val.hdf5\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 184.0923 - mean_absolute_error: 9.5368 - val_loss: 220.1838 - val_mean_absolute_error: 10.4331\n",
      "\n",
      "Epoch 00035: val_loss improved from 221.95703 to 220.18382, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model_test_val.hdf5\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 174.4525 - mean_absolute_error: 9.3569 - val_loss: 220.0330 - val_mean_absolute_error: 10.4412\n",
      "\n",
      "Epoch 00036: val_loss improved from 220.18382 to 220.03302, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model_test_val.hdf5\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 183.0977 - mean_absolute_error: 9.3582 - val_loss: 216.4909 - val_mean_absolute_error: 10.3958\n",
      "\n",
      "Epoch 00037: val_loss improved from 220.03302 to 216.49086, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model_test_val.hdf5\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 160.7521 - mean_absolute_error: 8.9084 - val_loss: 213.4460 - val_mean_absolute_error: 10.3678\n",
      "\n",
      "Epoch 00038: val_loss improved from 216.49086 to 213.44603, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model_test_val.hdf5\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 163.7341 - mean_absolute_error: 8.9762 - val_loss: 214.2725 - val_mean_absolute_error: 10.4147\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 213.44603\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 166.3001 - mean_absolute_error: 8.9545 - val_loss: 214.3135 - val_mean_absolute_error: 10.3010\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 213.44603\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 179.3401 - mean_absolute_error: 9.5597 - val_loss: 215.2328 - val_mean_absolute_error: 10.5041\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 213.44603\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 182.9100 - mean_absolute_error: 9.5948 - val_loss: 213.7646 - val_mean_absolute_error: 10.5148\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 213.44603\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 165.7227 - mean_absolute_error: 9.1127 - val_loss: 218.3783 - val_mean_absolute_error: 10.3153\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 213.44603\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 177.2967 - mean_absolute_error: 9.3494 - val_loss: 211.1331 - val_mean_absolute_error: 10.2997\n",
      "\n",
      "Epoch 00044: val_loss improved from 213.44603 to 211.13315, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model_test_val.hdf5\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 190.6263 - mean_absolute_error: 9.8210 - val_loss: 209.2359 - val_mean_absolute_error: 10.2680\n",
      "\n",
      "Epoch 00045: val_loss improved from 211.13315 to 209.23586, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model_test_val.hdf5\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 168.0033 - mean_absolute_error: 9.0288 - val_loss: 206.0680 - val_mean_absolute_error: 10.2664\n",
      "\n",
      "Epoch 00046: val_loss improved from 209.23586 to 206.06799, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model_test_val.hdf5\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 173.7424 - mean_absolute_error: 9.3128 - val_loss: 206.8485 - val_mean_absolute_error: 10.2180\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 206.06799\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 167.3427 - mean_absolute_error: 9.0947 - val_loss: 209.4377 - val_mean_absolute_error: 10.3039\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 206.06799\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 170.0263 - mean_absolute_error: 9.2404 - val_loss: 216.8516 - val_mean_absolute_error: 10.4028\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 206.06799\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 166.8572 - mean_absolute_error: 8.9945 - val_loss: 216.1871 - val_mean_absolute_error: 10.5850\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 206.06799\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 176.1052 - mean_absolute_error: 9.2301 - val_loss: 261.6956 - val_mean_absolute_error: 12.1232\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 206.06799\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 179.1195 - mean_absolute_error: 9.2687 - val_loss: 232.0540 - val_mean_absolute_error: 11.1969\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 206.06799\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 180.0811 - mean_absolute_error: 9.4624 - val_loss: 204.3883 - val_mean_absolute_error: 10.1789\n",
      "\n",
      "Epoch 00053: val_loss improved from 206.06799 to 204.38826, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model_test_val.hdf5\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 181.5999 - mean_absolute_error: 9.4960 - val_loss: 200.6980 - val_mean_absolute_error: 10.2014\n",
      "\n",
      "Epoch 00054: val_loss improved from 204.38826 to 200.69795, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model_test_val.hdf5\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 167.2515 - mean_absolute_error: 9.0512 - val_loss: 202.1919 - val_mean_absolute_error: 10.3974\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 200.69795\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 169.5697 - mean_absolute_error: 9.2504 - val_loss: 203.7685 - val_mean_absolute_error: 10.3120\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 200.69795\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 161.7434 - mean_absolute_error: 8.8230 - val_loss: 200.7081 - val_mean_absolute_error: 10.2549\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 200.69795\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 152.3687 - mean_absolute_error: 8.4882 - val_loss: 202.4226 - val_mean_absolute_error: 10.2156\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 200.69795\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 163.3063 - mean_absolute_error: 8.8499 - val_loss: 200.9630 - val_mean_absolute_error: 10.0439\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 200.69795\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 155.8165 - mean_absolute_error: 8.7177 - val_loss: 200.0627 - val_mean_absolute_error: 10.1532\n",
      "\n",
      "Epoch 00060: val_loss improved from 200.69795 to 200.06268, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model_test_val.hdf5\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 162.7194 - mean_absolute_error: 9.0477 - val_loss: 211.6240 - val_mean_absolute_error: 10.5992\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 200.06268\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 172.2539 - mean_absolute_error: 9.3069 - val_loss: 218.1897 - val_mean_absolute_error: 10.8116\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 200.06268\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 163.9058 - mean_absolute_error: 8.9687 - val_loss: 220.9826 - val_mean_absolute_error: 10.9349\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 200.06268\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 153.0874 - mean_absolute_error: 8.5435 - val_loss: 201.6976 - val_mean_absolute_error: 10.3019\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 200.06268\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 162.0330 - mean_absolute_error: 8.8574 - val_loss: 208.0121 - val_mean_absolute_error: 10.6506\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 200.06268\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 167.4277 - mean_absolute_error: 9.1281 - val_loss: 203.5875 - val_mean_absolute_error: 10.3689\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 200.06268\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 156.4975 - mean_absolute_error: 8.6786 - val_loss: 209.2542 - val_mean_absolute_error: 10.3919\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 200.06268\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 144.4001 - mean_absolute_error: 8.2877 - val_loss: 204.9778 - val_mean_absolute_error: 10.4556\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 200.06268\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 157.3082 - mean_absolute_error: 8.4995 - val_loss: 196.8201 - val_mean_absolute_error: 10.0227\n",
      "\n",
      "Epoch 00069: val_loss improved from 200.06268 to 196.82013, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model_test_val.hdf5\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 153.5032 - mean_absolute_error: 8.4671 - val_loss: 202.1546 - val_mean_absolute_error: 10.1632\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 196.82013\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 157.4372 - mean_absolute_error: 8.6442 - val_loss: 210.1347 - val_mean_absolute_error: 10.6147\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 196.82013\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 161.1714 - mean_absolute_error: 9.0507 - val_loss: 199.2213 - val_mean_absolute_error: 9.9786\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 196.82013\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 166.3986 - mean_absolute_error: 9.0903 - val_loss: 200.1525 - val_mean_absolute_error: 10.1802\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 196.82013\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 156.6131 - mean_absolute_error: 8.4831 - val_loss: 197.6558 - val_mean_absolute_error: 10.1075\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 196.82013\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 160.0412 - mean_absolute_error: 8.8064 - val_loss: 196.2167 - val_mean_absolute_error: 10.0640\n",
      "\n",
      "Epoch 00075: val_loss improved from 196.82013 to 196.21671, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model_test_val.hdf5\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 162.4771 - mean_absolute_error: 8.8405 - val_loss: 199.4353 - val_mean_absolute_error: 10.1603\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 196.21671\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 168.2897 - mean_absolute_error: 8.9701 - val_loss: 199.2598 - val_mean_absolute_error: 10.0864\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 196.21671\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 144.8003 - mean_absolute_error: 8.1905 - val_loss: 195.1837 - val_mean_absolute_error: 10.0157\n",
      "\n",
      "Epoch 00078: val_loss improved from 196.21671 to 195.18373, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model_test_val.hdf5\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 170.5347 - mean_absolute_error: 8.9231 - val_loss: 195.8645 - val_mean_absolute_error: 9.9739\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 195.18373\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 162.9027 - mean_absolute_error: 8.9041 - val_loss: 204.9629 - val_mean_absolute_error: 10.3553\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 195.18373\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 147.4693 - mean_absolute_error: 8.5073 - val_loss: 205.8157 - val_mean_absolute_error: 10.2530\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 195.18373\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 140.7398 - mean_absolute_error: 7.8561 - val_loss: 203.8438 - val_mean_absolute_error: 10.4101\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 195.18373\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 150.7170 - mean_absolute_error: 8.4826 - val_loss: 196.5619 - val_mean_absolute_error: 10.1005\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 195.18373\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 143.5356 - mean_absolute_error: 8.1530 - val_loss: 196.9911 - val_mean_absolute_error: 10.1370\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 195.18373\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 153.0777 - mean_absolute_error: 8.6257 - val_loss: 211.4289 - val_mean_absolute_error: 10.6245\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 195.18373\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 142.6942 - mean_absolute_error: 8.2243 - val_loss: 197.7112 - val_mean_absolute_error: 10.0878\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 195.18373\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 149.6202 - mean_absolute_error: 8.3703 - val_loss: 199.3555 - val_mean_absolute_error: 10.1391\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 195.18373\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 145.7572 - mean_absolute_error: 8.1656 - val_loss: 203.9732 - val_mean_absolute_error: 10.4684\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 195.18373\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 143.4544 - mean_absolute_error: 8.0593 - val_loss: 203.8364 - val_mean_absolute_error: 10.3070\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 195.18373\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 150.1904 - mean_absolute_error: 8.5746 - val_loss: 203.6201 - val_mean_absolute_error: 10.4199\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 195.18373\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 167.0132 - mean_absolute_error: 9.0114 - val_loss: 195.2814 - val_mean_absolute_error: 10.1050\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 195.18373\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 158.1968 - mean_absolute_error: 8.6122 - val_loss: 214.3362 - val_mean_absolute_error: 10.3577\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 195.18373\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 159.8400 - mean_absolute_error: 8.7009 - val_loss: 202.7173 - val_mean_absolute_error: 10.1277\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 195.18373\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 155.9110 - mean_absolute_error: 8.5676 - val_loss: 194.1864 - val_mean_absolute_error: 9.9983\n",
      "\n",
      "Epoch 00094: val_loss improved from 195.18373 to 194.18637, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model_test_val.hdf5\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 151.7000 - mean_absolute_error: 8.3325 - val_loss: 199.4394 - val_mean_absolute_error: 10.0526\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 194.18637\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 144.8058 - mean_absolute_error: 8.2663 - val_loss: 195.6403 - val_mean_absolute_error: 10.1182\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 194.18637\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 146.8831 - mean_absolute_error: 8.1347 - val_loss: 195.6098 - val_mean_absolute_error: 10.0634\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 194.18637\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 139.4702 - mean_absolute_error: 7.8809 - val_loss: 194.9816 - val_mean_absolute_error: 10.0508\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 194.18637\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 131.1945 - mean_absolute_error: 7.6034 - val_loss: 203.8426 - val_mean_absolute_error: 10.2405\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 194.18637\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 137.6961 - mean_absolute_error: 7.6348 - val_loss: 206.6116 - val_mean_absolute_error: 10.4248\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 194.18637\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 150.0336 - mean_absolute_error: 8.4218 - val_loss: 203.0945 - val_mean_absolute_error: 10.1969\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 194.18637\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 152.7111 - mean_absolute_error: 8.2575 - val_loss: 196.7854 - val_mean_absolute_error: 10.1137\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 194.18637\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 142.4107 - mean_absolute_error: 8.1972 - val_loss: 199.5365 - val_mean_absolute_error: 10.0489\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 194.18637\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 139.4551 - mean_absolute_error: 8.1287 - val_loss: 202.0301 - val_mean_absolute_error: 10.2039\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 194.18637\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 147.0104 - mean_absolute_error: 8.3139 - val_loss: 202.4515 - val_mean_absolute_error: 10.2709\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 194.18637\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 148.5897 - mean_absolute_error: 8.3479 - val_loss: 201.3606 - val_mean_absolute_error: 10.2234\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 194.18637\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 132.5456 - mean_absolute_error: 7.7426 - val_loss: 204.7993 - val_mean_absolute_error: 10.4204\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 194.18637\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 137.7984 - mean_absolute_error: 7.9454 - val_loss: 208.8691 - val_mean_absolute_error: 10.5715\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 194.18637\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 140.8142 - mean_absolute_error: 8.0506 - val_loss: 201.8306 - val_mean_absolute_error: 10.2106\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 194.18637\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 133.3725 - mean_absolute_error: 7.6659 - val_loss: 206.4859 - val_mean_absolute_error: 10.3236\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 194.18637\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 158.7335 - mean_absolute_error: 8.5777 - val_loss: 216.2256 - val_mean_absolute_error: 10.8685\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 194.18637\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 145.2256 - mean_absolute_error: 8.2602 - val_loss: 203.4066 - val_mean_absolute_error: 10.2304\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 194.18637\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 136.3673 - mean_absolute_error: 7.9310 - val_loss: 198.9707 - val_mean_absolute_error: 10.1072\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 194.18637\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 151.5192 - mean_absolute_error: 8.4369 - val_loss: 208.1982 - val_mean_absolute_error: 10.2306\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 194.18637\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 136.1430 - mean_absolute_error: 7.9638 - val_loss: 200.9969 - val_mean_absolute_error: 9.9302\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 194.18637\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 140.8490 - mean_absolute_error: 7.9888 - val_loss: 203.0684 - val_mean_absolute_error: 10.3382\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 194.18637\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 131.0877 - mean_absolute_error: 7.7053 - val_loss: 193.3196 - val_mean_absolute_error: 9.8480\n",
      "\n",
      "Epoch 00117: val_loss improved from 194.18637 to 193.31964, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model_test_val.hdf5\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 131.6016 - mean_absolute_error: 7.8383 - val_loss: 198.0778 - val_mean_absolute_error: 10.0839\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 193.31964\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 144.5955 - mean_absolute_error: 8.0846 - val_loss: 211.8507 - val_mean_absolute_error: 10.6381\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 193.31964\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 145.5426 - mean_absolute_error: 8.1303 - val_loss: 207.2296 - val_mean_absolute_error: 10.4156\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 193.31964\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 129.9010 - mean_absolute_error: 7.6151 - val_loss: 201.8562 - val_mean_absolute_error: 10.3100\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 193.31964\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 145.3295 - mean_absolute_error: 8.2591 - val_loss: 199.5849 - val_mean_absolute_error: 10.0340\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 193.31964\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 156.1445 - mean_absolute_error: 8.4180 - val_loss: 200.5755 - val_mean_absolute_error: 10.0959\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 193.31964\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 145.2499 - mean_absolute_error: 8.1247 - val_loss: 196.0644 - val_mean_absolute_error: 9.9950\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 193.31964\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 132.9902 - mean_absolute_error: 7.8027 - val_loss: 197.5456 - val_mean_absolute_error: 10.0728\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 193.31964\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 151.5087 - mean_absolute_error: 8.2590 - val_loss: 208.5858 - val_mean_absolute_error: 10.4615\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 193.31964\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 146.0725 - mean_absolute_error: 8.4218 - val_loss: 221.6260 - val_mean_absolute_error: 11.0323\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 193.31964\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 162.3754 - mean_absolute_error: 8.8262 - val_loss: 192.3364 - val_mean_absolute_error: 9.9471\n",
      "\n",
      "Epoch 00128: val_loss improved from 193.31964 to 192.33636, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model_test_val.hdf5\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 137.5707 - mean_absolute_error: 7.9113 - val_loss: 207.1006 - val_mean_absolute_error: 10.4794\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 192.33636\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 139.0252 - mean_absolute_error: 8.0172 - val_loss: 203.8401 - val_mean_absolute_error: 10.3722\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 192.33636\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 137.9791 - mean_absolute_error: 7.6226 - val_loss: 201.4870 - val_mean_absolute_error: 10.4327\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 192.33636\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 154.0175 - mean_absolute_error: 8.3318 - val_loss: 206.6857 - val_mean_absolute_error: 10.5361\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 192.33636\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 141.0749 - mean_absolute_error: 8.0654 - val_loss: 201.8011 - val_mean_absolute_error: 10.1243\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 192.33636\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 137.0414 - mean_absolute_error: 7.8501 - val_loss: 202.3677 - val_mean_absolute_error: 10.3330\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 192.33636\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 153.5305 - mean_absolute_error: 8.1389 - val_loss: 217.3990 - val_mean_absolute_error: 10.8193\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 192.33636\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 142.1032 - mean_absolute_error: 8.0570 - val_loss: 202.1592 - val_mean_absolute_error: 10.3687\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 192.33636\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 131.2035 - mean_absolute_error: 7.7255 - val_loss: 207.4405 - val_mean_absolute_error: 10.5144\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 192.33636\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 122.2004 - mean_absolute_error: 7.4135 - val_loss: 208.8059 - val_mean_absolute_error: 10.5245\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 192.33636\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 136.7072 - mean_absolute_error: 7.9264 - val_loss: 207.7202 - val_mean_absolute_error: 10.3732\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 192.33636\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 137.8637 - mean_absolute_error: 7.9394 - val_loss: 205.8166 - val_mean_absolute_error: 10.2453\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 192.33636\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 125.4050 - mean_absolute_error: 7.4451 - val_loss: 211.8599 - val_mean_absolute_error: 10.3836\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 192.33636\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 126.7147 - mean_absolute_error: 7.3441 - val_loss: 202.0564 - val_mean_absolute_error: 10.2714\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 192.33636\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 128.0214 - mean_absolute_error: 7.4266 - val_loss: 203.2543 - val_mean_absolute_error: 10.4361\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 192.33636\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 136.2713 - mean_absolute_error: 7.5903 - val_loss: 201.0219 - val_mean_absolute_error: 10.2588\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 192.33636\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 129.4439 - mean_absolute_error: 7.5980 - val_loss: 205.0483 - val_mean_absolute_error: 10.2439\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 192.33636\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 126.1115 - mean_absolute_error: 7.2719 - val_loss: 204.9104 - val_mean_absolute_error: 10.3782\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 192.33636\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 131.1125 - mean_absolute_error: 7.3840 - val_loss: 207.5765 - val_mean_absolute_error: 10.3642\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 192.33636\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 124.7797 - mean_absolute_error: 7.4759 - val_loss: 205.4940 - val_mean_absolute_error: 10.1946\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 192.33636\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 136.0670 - mean_absolute_error: 7.8595 - val_loss: 214.0929 - val_mean_absolute_error: 10.5845\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 192.33636\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 132.7941 - mean_absolute_error: 7.7685 - val_loss: 211.0317 - val_mean_absolute_error: 10.6689\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 192.33636\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 133.8733 - mean_absolute_error: 7.3823 - val_loss: 209.2713 - val_mean_absolute_error: 10.5418\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 192.33636\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 131.7023 - mean_absolute_error: 7.5850 - val_loss: 203.1349 - val_mean_absolute_error: 10.2847\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 192.33636\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 133.9715 - mean_absolute_error: 7.6055 - val_loss: 208.3655 - val_mean_absolute_error: 10.5041\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 192.33636\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 129.9625 - mean_absolute_error: 7.6174 - val_loss: 205.5128 - val_mean_absolute_error: 10.3206\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 192.33636\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 112.4929 - mean_absolute_error: 6.9744 - val_loss: 211.5735 - val_mean_absolute_error: 10.5928\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 192.33636\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 141.4322 - mean_absolute_error: 7.8851 - val_loss: 211.7930 - val_mean_absolute_error: 10.6203\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 192.33636\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 132.7012 - mean_absolute_error: 7.5146 - val_loss: 212.0643 - val_mean_absolute_error: 10.7254\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 192.33636\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 128.2556 - mean_absolute_error: 7.5152 - val_loss: 222.4328 - val_mean_absolute_error: 11.0732\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 192.33636\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 141.8931 - mean_absolute_error: 8.0776 - val_loss: 207.0411 - val_mean_absolute_error: 10.5006\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 192.33636\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 127.4362 - mean_absolute_error: 7.3479 - val_loss: 207.3923 - val_mean_absolute_error: 10.3330\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 192.33636\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 126.8208 - mean_absolute_error: 7.3501 - val_loss: 208.2423 - val_mean_absolute_error: 10.3461\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 192.33636\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 131.7932 - mean_absolute_error: 7.5057 - val_loss: 212.8888 - val_mean_absolute_error: 10.5958\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 192.33636\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 127.1289 - mean_absolute_error: 7.5498 - val_loss: 218.2571 - val_mean_absolute_error: 10.6137\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 192.33636\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 125.1159 - mean_absolute_error: 7.2817 - val_loss: 206.3385 - val_mean_absolute_error: 10.4484\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 192.33636\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 123.2501 - mean_absolute_error: 7.3041 - val_loss: 204.0358 - val_mean_absolute_error: 10.2954\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 192.33636\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 139.2391 - mean_absolute_error: 7.7682 - val_loss: 206.1398 - val_mean_absolute_error: 10.4789\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 192.33636\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 134.2459 - mean_absolute_error: 7.6836 - val_loss: 207.1741 - val_mean_absolute_error: 10.2996\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 192.33636\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 122.0553 - mean_absolute_error: 7.2278 - val_loss: 209.7009 - val_mean_absolute_error: 10.4497\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 192.33636\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 127.3345 - mean_absolute_error: 7.2784 - val_loss: 210.1703 - val_mean_absolute_error: 10.3756\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 192.33636\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 133.4881 - mean_absolute_error: 7.6666 - val_loss: 208.5718 - val_mean_absolute_error: 10.4860\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 192.33636\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 125.2960 - mean_absolute_error: 7.3476 - val_loss: 209.3082 - val_mean_absolute_error: 10.5530\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 192.33636\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 128.6439 - mean_absolute_error: 7.5498 - val_loss: 240.4397 - val_mean_absolute_error: 11.6664\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 192.33636\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 160.1747 - mean_absolute_error: 8.5382 - val_loss: 236.8868 - val_mean_absolute_error: 11.3399\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 192.33636\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 141.0383 - mean_absolute_error: 7.8482 - val_loss: 206.0640 - val_mean_absolute_error: 10.3538\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 192.33636\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 131.6276 - mean_absolute_error: 7.5354 - val_loss: 203.9662 - val_mean_absolute_error: 10.3448\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 192.33636\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 124.3711 - mean_absolute_error: 7.2209 - val_loss: 206.6077 - val_mean_absolute_error: 10.3782\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 192.33636\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 131.7174 - mean_absolute_error: 7.6447 - val_loss: 211.9278 - val_mean_absolute_error: 10.5295\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 192.33636\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 125.5858 - mean_absolute_error: 7.2915 - val_loss: 226.9914 - val_mean_absolute_error: 11.1610\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 192.33636\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 133.3044 - mean_absolute_error: 7.5153 - val_loss: 214.2781 - val_mean_absolute_error: 10.5573\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 192.33636\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 128.3020 - mean_absolute_error: 7.3941 - val_loss: 212.5998 - val_mean_absolute_error: 10.4914\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 192.33636\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 121.1276 - mean_absolute_error: 7.1707 - val_loss: 213.8463 - val_mean_absolute_error: 10.6530\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 192.33636\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 135.6587 - mean_absolute_error: 7.5548 - val_loss: 209.5140 - val_mean_absolute_error: 10.4809\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 192.33636\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 121.5838 - mean_absolute_error: 7.3045 - val_loss: 210.9215 - val_mean_absolute_error: 10.4732\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 192.33636\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 115.6662 - mean_absolute_error: 7.0003 - val_loss: 213.3916 - val_mean_absolute_error: 10.5705\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 192.33636\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 120.6145 - mean_absolute_error: 7.0790 - val_loss: 213.6843 - val_mean_absolute_error: 10.7620\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 192.33636\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 129.7732 - mean_absolute_error: 7.4426 - val_loss: 205.1272 - val_mean_absolute_error: 10.4777\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 192.33636\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 130.3877 - mean_absolute_error: 7.4848 - val_loss: 210.6698 - val_mean_absolute_error: 10.6298\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 192.33636\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 132.9385 - mean_absolute_error: 7.7006 - val_loss: 224.8916 - val_mean_absolute_error: 11.1053\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 192.33636\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 123.2675 - mean_absolute_error: 7.1689 - val_loss: 213.8704 - val_mean_absolute_error: 10.6963\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 192.33636\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 117.4648 - mean_absolute_error: 7.0602 - val_loss: 216.4483 - val_mean_absolute_error: 10.8336\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 192.33636\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 127.6461 - mean_absolute_error: 7.4056 - val_loss: 209.5464 - val_mean_absolute_error: 10.4047\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 192.33636\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 124.8396 - mean_absolute_error: 7.1129 - val_loss: 215.1042 - val_mean_absolute_error: 10.7437\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 192.33636\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 122.1891 - mean_absolute_error: 7.1188 - val_loss: 222.6522 - val_mean_absolute_error: 11.0525\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 192.33636\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 128.8265 - mean_absolute_error: 7.3391 - val_loss: 222.5750 - val_mean_absolute_error: 11.0831\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 192.33636\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 129.5082 - mean_absolute_error: 7.5165 - val_loss: 210.5243 - val_mean_absolute_error: 10.6387\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 192.33636\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 120.7372 - mean_absolute_error: 7.1941 - val_loss: 214.4779 - val_mean_absolute_error: 10.9011\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 192.33636\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 122.2334 - mean_absolute_error: 7.1179 - val_loss: 220.7138 - val_mean_absolute_error: 10.8302\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 192.33636\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 123.5932 - mean_absolute_error: 7.2516 - val_loss: 212.7598 - val_mean_absolute_error: 10.6275\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 192.33636\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 117.0439 - mean_absolute_error: 6.8770 - val_loss: 208.2227 - val_mean_absolute_error: 10.4586\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 192.33636\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 125.5665 - mean_absolute_error: 7.3509 - val_loss: 208.4327 - val_mean_absolute_error: 10.5165\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 192.33636\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 132.5040 - mean_absolute_error: 7.3900 - val_loss: 204.8278 - val_mean_absolute_error: 10.5019\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 192.33636\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 123.8801 - mean_absolute_error: 7.2394 - val_loss: 207.3013 - val_mean_absolute_error: 10.4214\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 192.33636\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 114.4352 - mean_absolute_error: 6.8010 - val_loss: 210.5863 - val_mean_absolute_error: 10.6646\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 192.33636\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 125.4627 - mean_absolute_error: 7.3197 - val_loss: 227.9670 - val_mean_absolute_error: 11.1644\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 192.33636\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 129.7999 - mean_absolute_error: 7.4039 - val_loss: 219.1823 - val_mean_absolute_error: 10.8793\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 192.33636\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 133.2844 - mean_absolute_error: 7.4255 - val_loss: 208.6579 - val_mean_absolute_error: 10.3024\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 192.33636\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 133.1602 - mean_absolute_error: 7.6738 - val_loss: 224.8871 - val_mean_absolute_error: 10.6841\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 192.33636\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 125.6643 - mean_absolute_error: 7.3881 - val_loss: 210.8513 - val_mean_absolute_error: 10.4581\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 192.33636\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 116.7413 - mean_absolute_error: 6.9159 - val_loss: 211.6909 - val_mean_absolute_error: 10.7509\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 192.33636\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 129.4638 - mean_absolute_error: 7.3720 - val_loss: 221.4626 - val_mean_absolute_error: 10.9003\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 192.33636\n",
      "Epoch 211/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 134.1709 - mean_absolute_error: 7.3968 - val_loss: 232.3004 - val_mean_absolute_error: 11.4738\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 192.33636\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 133.4074 - mean_absolute_error: 7.4106 - val_loss: 212.4066 - val_mean_absolute_error: 10.7071\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 192.33636\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 121.6004 - mean_absolute_error: 6.9442 - val_loss: 216.1510 - val_mean_absolute_error: 10.4833\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 192.33636\n",
      "Epoch 214/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 125.5551 - mean_absolute_error: 7.2058 - val_loss: 213.1747 - val_mean_absolute_error: 10.6999\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 192.33636\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 125.8390 - mean_absolute_error: 7.2412 - val_loss: 215.0627 - val_mean_absolute_error: 10.9387\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 192.33636\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 125.8510 - mean_absolute_error: 7.3288 - val_loss: 220.1429 - val_mean_absolute_error: 10.9852\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 192.33636\n",
      "Epoch 217/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 125.3232 - mean_absolute_error: 7.1663 - val_loss: 217.9835 - val_mean_absolute_error: 10.8882\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 192.33636\n",
      "Epoch 218/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 118.3846 - mean_absolute_error: 6.8422 - val_loss: 218.8379 - val_mean_absolute_error: 10.8749\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 192.33636\n",
      "Epoch 219/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 125.7799 - mean_absolute_error: 7.1796 - val_loss: 214.6692 - val_mean_absolute_error: 10.7293\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 192.33636\n",
      "Epoch 220/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 120.7657 - mean_absolute_error: 7.1334 - val_loss: 208.6275 - val_mean_absolute_error: 10.3351\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 192.33636\n",
      "Epoch 221/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 119.9222 - mean_absolute_error: 6.9895 - val_loss: 207.1764 - val_mean_absolute_error: 10.5120\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 192.33636\n",
      "Epoch 222/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 119.3601 - mean_absolute_error: 6.9259 - val_loss: 207.9669 - val_mean_absolute_error: 10.4131\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 192.33636\n",
      "Epoch 223/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 119.6095 - mean_absolute_error: 7.0401 - val_loss: 211.9594 - val_mean_absolute_error: 10.5702\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 192.33636\n",
      "Epoch 224/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 113.2385 - mean_absolute_error: 6.7292 - val_loss: 211.1713 - val_mean_absolute_error: 10.5112\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 192.33636\n",
      "Epoch 225/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 114.6564 - mean_absolute_error: 6.9606 - val_loss: 212.2922 - val_mean_absolute_error: 10.5217\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 192.33636\n",
      "Epoch 226/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 108.9192 - mean_absolute_error: 6.6314 - val_loss: 216.9370 - val_mean_absolute_error: 10.8644\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 192.33636\n",
      "Epoch 227/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 111.9317 - mean_absolute_error: 6.6209 - val_loss: 215.5397 - val_mean_absolute_error: 10.8915\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 192.33636\n",
      "Epoch 228/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 119.7297 - mean_absolute_error: 6.9554 - val_loss: 211.5649 - val_mean_absolute_error: 10.6434\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 192.33636\n",
      "Epoch 229/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 127.6968 - mean_absolute_error: 7.2117 - val_loss: 212.9359 - val_mean_absolute_error: 10.4983\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 192.33636\n",
      "Epoch 230/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 126.1187 - mean_absolute_error: 7.3727 - val_loss: 210.5506 - val_mean_absolute_error: 10.3953\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 192.33636\n",
      "Epoch 231/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 133.1226 - mean_absolute_error: 7.4533 - val_loss: 216.7750 - val_mean_absolute_error: 10.8172\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 192.33636\n",
      "Epoch 232/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 132.6964 - mean_absolute_error: 7.4518 - val_loss: 214.5479 - val_mean_absolute_error: 10.7090\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 192.33636\n",
      "Epoch 233/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 121.0296 - mean_absolute_error: 7.0772 - val_loss: 215.2589 - val_mean_absolute_error: 10.7987\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 192.33636\n",
      "Epoch 234/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 124.9309 - mean_absolute_error: 7.3135 - val_loss: 213.6123 - val_mean_absolute_error: 10.4938\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 192.33636\n",
      "Epoch 235/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 114.6517 - mean_absolute_error: 6.5915 - val_loss: 209.4836 - val_mean_absolute_error: 10.4223\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 192.33636\n",
      "Epoch 236/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 126.6976 - mean_absolute_error: 7.0232 - val_loss: 214.0255 - val_mean_absolute_error: 10.5461\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 192.33636\n",
      "Epoch 237/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 120.0742 - mean_absolute_error: 7.1095 - val_loss: 211.1156 - val_mean_absolute_error: 10.6267\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 192.33636\n",
      "Epoch 238/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 124.5395 - mean_absolute_error: 7.0296 - val_loss: 215.8700 - val_mean_absolute_error: 10.5046\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 192.33636\n",
      "Epoch 239/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 119.4819 - mean_absolute_error: 6.9470 - val_loss: 215.1595 - val_mean_absolute_error: 10.5034\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 192.33636\n",
      "Epoch 240/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 119.6588 - mean_absolute_error: 7.0314 - val_loss: 215.5300 - val_mean_absolute_error: 10.5872\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 192.33636\n",
      "Epoch 241/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 113.3925 - mean_absolute_error: 6.7342 - val_loss: 222.4992 - val_mean_absolute_error: 10.7041\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 192.33636\n",
      "Epoch 242/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 121.5321 - mean_absolute_error: 7.0949 - val_loss: 217.7491 - val_mean_absolute_error: 10.6091\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 192.33636\n",
      "Epoch 243/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 111.1567 - mean_absolute_error: 6.6257 - val_loss: 218.7088 - val_mean_absolute_error: 10.7949\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 192.33636\n",
      "Epoch 244/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 118.5067 - mean_absolute_error: 7.1073 - val_loss: 217.5550 - val_mean_absolute_error: 10.8254\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 192.33636\n",
      "Epoch 245/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 126.3271 - mean_absolute_error: 7.2911 - val_loss: 212.3839 - val_mean_absolute_error: 10.7118\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 192.33636\n",
      "Epoch 246/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 124.7893 - mean_absolute_error: 7.3686 - val_loss: 215.5689 - val_mean_absolute_error: 10.5812\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 192.33636\n",
      "Epoch 247/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 128.3038 - mean_absolute_error: 7.2571 - val_loss: 222.0573 - val_mean_absolute_error: 10.6937\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 192.33636\n",
      "Epoch 248/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 144.9672 - mean_absolute_error: 7.9183 - val_loss: 212.4636 - val_mean_absolute_error: 10.4819\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 192.33636\n",
      "Epoch 249/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 124.8690 - mean_absolute_error: 7.2310 - val_loss: 210.0993 - val_mean_absolute_error: 10.3976\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 192.33636\n",
      "Epoch 250/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 114.8586 - mean_absolute_error: 6.7893 - val_loss: 216.5560 - val_mean_absolute_error: 10.7409\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 192.33636\n",
      "Epoch 251/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 115.1077 - mean_absolute_error: 6.7667 - val_loss: 213.6697 - val_mean_absolute_error: 10.6222\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 192.33636\n",
      "Epoch 252/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 122.2588 - mean_absolute_error: 6.9639 - val_loss: 217.1392 - val_mean_absolute_error: 10.6603\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 192.33636\n",
      "Epoch 253/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 116.5742 - mean_absolute_error: 6.7662 - val_loss: 214.3239 - val_mean_absolute_error: 10.5768\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 192.33636\n",
      "Epoch 254/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 116.0707 - mean_absolute_error: 6.6682 - val_loss: 217.1733 - val_mean_absolute_error: 10.7500\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 192.33636\n",
      "Epoch 255/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 118.2857 - mean_absolute_error: 6.9813 - val_loss: 216.8537 - val_mean_absolute_error: 10.6793\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 192.33636\n",
      "Epoch 256/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 125.0468 - mean_absolute_error: 7.1903 - val_loss: 214.0272 - val_mean_absolute_error: 10.6697\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 192.33636\n",
      "Epoch 257/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 110.7526 - mean_absolute_error: 6.7351 - val_loss: 218.2330 - val_mean_absolute_error: 10.8042\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 192.33636\n",
      "Epoch 258/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 116.3487 - mean_absolute_error: 6.8843 - val_loss: 221.8445 - val_mean_absolute_error: 10.9386\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 192.33636\n",
      "Epoch 259/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 117.1229 - mean_absolute_error: 6.8704 - val_loss: 217.0359 - val_mean_absolute_error: 10.5810\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 192.33636\n",
      "Epoch 260/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 117.6907 - mean_absolute_error: 6.9029 - val_loss: 209.9427 - val_mean_absolute_error: 10.4370\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 192.33636\n",
      "Epoch 261/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 117.7110 - mean_absolute_error: 6.9485 - val_loss: 214.4059 - val_mean_absolute_error: 10.7312\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 192.33636\n",
      "Epoch 262/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 122.1096 - mean_absolute_error: 6.9030 - val_loss: 225.4940 - val_mean_absolute_error: 11.2424\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 192.33636\n",
      "Epoch 263/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 118.4131 - mean_absolute_error: 7.0393 - val_loss: 223.9456 - val_mean_absolute_error: 11.0544\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 192.33636\n",
      "Epoch 264/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 120.8244 - mean_absolute_error: 6.8922 - val_loss: 216.3940 - val_mean_absolute_error: 10.6853\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 192.33636\n",
      "Epoch 265/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 123.3967 - mean_absolute_error: 6.9287 - val_loss: 221.2898 - val_mean_absolute_error: 10.7425\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 192.33636\n",
      "Epoch 266/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 127.0186 - mean_absolute_error: 7.2680 - val_loss: 237.4322 - val_mean_absolute_error: 11.1447\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 192.33636\n",
      "Epoch 267/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 127.5849 - mean_absolute_error: 7.3975 - val_loss: 221.0645 - val_mean_absolute_error: 10.7502\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 192.33636\n",
      "Epoch 268/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 124.5762 - mean_absolute_error: 7.1955 - val_loss: 224.2838 - val_mean_absolute_error: 10.9991\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 192.33636\n",
      "Epoch 269/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 120.6397 - mean_absolute_error: 7.1516 - val_loss: 224.9680 - val_mean_absolute_error: 10.9879\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 192.33636\n",
      "Epoch 270/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 124.1822 - mean_absolute_error: 7.0261 - val_loss: 225.5860 - val_mean_absolute_error: 11.2084\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 192.33636\n",
      "Epoch 271/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 120.1637 - mean_absolute_error: 6.9787 - val_loss: 236.9323 - val_mean_absolute_error: 11.6931\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 192.33636\n",
      "Epoch 272/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 127.2031 - mean_absolute_error: 7.3480 - val_loss: 228.8707 - val_mean_absolute_error: 11.2336\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 192.33636\n",
      "Epoch 273/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 113.2335 - mean_absolute_error: 6.6912 - val_loss: 226.0231 - val_mean_absolute_error: 10.8612\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 192.33636\n",
      "Epoch 274/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 120.9112 - mean_absolute_error: 6.9422 - val_loss: 224.2981 - val_mean_absolute_error: 10.8184\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 192.33636\n",
      "Epoch 275/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 114.8785 - mean_absolute_error: 6.7704 - val_loss: 227.9474 - val_mean_absolute_error: 11.1801\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 192.33636\n",
      "Epoch 276/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 137.4420 - mean_absolute_error: 7.7070 - val_loss: 229.0054 - val_mean_absolute_error: 11.2834\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 192.33636\n",
      "Epoch 277/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 117.3840 - mean_absolute_error: 6.8832 - val_loss: 241.7678 - val_mean_absolute_error: 11.7303\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 192.33636\n",
      "Epoch 278/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 124.6031 - mean_absolute_error: 7.1410 - val_loss: 222.4896 - val_mean_absolute_error: 10.9961\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 192.33636\n",
      "Epoch 279/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 121.9770 - mean_absolute_error: 6.8979 - val_loss: 220.5654 - val_mean_absolute_error: 10.7312\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 192.33636\n",
      "Epoch 280/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 114.4324 - mean_absolute_error: 6.6509 - val_loss: 224.2580 - val_mean_absolute_error: 10.9600\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 192.33636\n",
      "Epoch 281/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 120.7314 - mean_absolute_error: 6.9084 - val_loss: 227.1372 - val_mean_absolute_error: 11.0774\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 192.33636\n",
      "Epoch 282/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 113.5368 - mean_absolute_error: 6.8878 - val_loss: 220.1968 - val_mean_absolute_error: 10.7235\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 192.33636\n",
      "Epoch 283/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 116.5442 - mean_absolute_error: 6.7890 - val_loss: 223.3650 - val_mean_absolute_error: 10.9629\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 192.33636\n",
      "Epoch 284/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 109.4630 - mean_absolute_error: 6.6243 - val_loss: 221.1687 - val_mean_absolute_error: 10.9224\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 192.33636\n",
      "Epoch 285/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 104.0950 - mean_absolute_error: 6.4606 - val_loss: 217.6219 - val_mean_absolute_error: 10.8339\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 192.33636\n",
      "Epoch 286/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 115.6596 - mean_absolute_error: 6.7220 - val_loss: 215.9297 - val_mean_absolute_error: 10.6213\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 192.33636\n",
      "Epoch 287/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 120.4426 - mean_absolute_error: 7.0251 - val_loss: 217.0868 - val_mean_absolute_error: 10.7192\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 192.33636\n",
      "Epoch 288/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 111.3369 - mean_absolute_error: 6.6163 - val_loss: 228.8484 - val_mean_absolute_error: 11.2488\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 192.33636\n",
      "Epoch 289/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 111.5771 - mean_absolute_error: 6.4616 - val_loss: 225.1584 - val_mean_absolute_error: 11.1370\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 192.33636\n",
      "Epoch 290/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 112.6236 - mean_absolute_error: 6.6347 - val_loss: 225.4036 - val_mean_absolute_error: 11.0601\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 192.33636\n",
      "Epoch 291/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 114.5781 - mean_absolute_error: 6.7189 - val_loss: 228.0633 - val_mean_absolute_error: 11.0789\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 192.33636\n",
      "Epoch 292/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 109.2612 - mean_absolute_error: 6.5290 - val_loss: 227.6739 - val_mean_absolute_error: 11.2101\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 192.33636\n",
      "Epoch 293/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 132.0313 - mean_absolute_error: 7.3583 - val_loss: 230.2535 - val_mean_absolute_error: 11.2781\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 192.33636\n",
      "Epoch 294/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 111.3936 - mean_absolute_error: 6.5264 - val_loss: 229.3532 - val_mean_absolute_error: 11.1893\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 192.33636\n",
      "Epoch 295/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 107.7642 - mean_absolute_error: 6.6600 - val_loss: 221.8933 - val_mean_absolute_error: 10.7410\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 192.33636\n",
      "Epoch 296/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 118.4014 - mean_absolute_error: 6.9852 - val_loss: 232.7336 - val_mean_absolute_error: 11.0041\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 192.33636\n",
      "Epoch 297/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 125.3371 - mean_absolute_error: 7.0569 - val_loss: 236.5540 - val_mean_absolute_error: 11.0374\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 192.33636\n",
      "Epoch 298/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 113.4340 - mean_absolute_error: 6.7247 - val_loss: 221.4351 - val_mean_absolute_error: 10.7464\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 192.33636\n",
      "Epoch 299/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 119.9978 - mean_absolute_error: 6.8784 - val_loss: 223.7523 - val_mean_absolute_error: 10.8958\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 192.33636\n",
      "Epoch 300/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 117.8685 - mean_absolute_error: 6.7382 - val_loss: 225.6883 - val_mean_absolute_error: 10.9370\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 192.33636\n",
      "Epoch 301/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 123.5296 - mean_absolute_error: 6.8733 - val_loss: 221.5924 - val_mean_absolute_error: 10.8863\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 192.33636\n",
      "Epoch 302/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 118.1521 - mean_absolute_error: 6.8243 - val_loss: 229.1756 - val_mean_absolute_error: 10.9992\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 192.33636\n",
      "Epoch 303/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 110.5752 - mean_absolute_error: 6.5930 - val_loss: 238.0885 - val_mean_absolute_error: 11.1309\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 192.33636\n",
      "Epoch 304/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 123.5261 - mean_absolute_error: 6.7616 - val_loss: 224.6770 - val_mean_absolute_error: 11.0042\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 192.33636\n",
      "Epoch 305/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 116.7978 - mean_absolute_error: 6.5147 - val_loss: 230.2679 - val_mean_absolute_error: 11.2323\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 192.33636\n",
      "Epoch 306/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 112.6938 - mean_absolute_error: 6.5420 - val_loss: 225.5002 - val_mean_absolute_error: 11.0081\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 192.33636\n",
      "Epoch 307/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 104.9441 - mean_absolute_error: 6.2896 - val_loss: 229.4720 - val_mean_absolute_error: 11.2912\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 192.33636\n",
      "Epoch 308/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 107.4006 - mean_absolute_error: 6.3997 - val_loss: 239.4372 - val_mean_absolute_error: 11.5273\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 192.33636\n",
      "Epoch 309/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 108.8493 - mean_absolute_error: 6.5223 - val_loss: 237.4552 - val_mean_absolute_error: 11.5273\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 192.33636\n",
      "Epoch 310/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 121.0512 - mean_absolute_error: 7.0335 - val_loss: 231.3129 - val_mean_absolute_error: 11.0388\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 192.33636\n",
      "Epoch 311/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 114.8116 - mean_absolute_error: 6.7044 - val_loss: 227.1977 - val_mean_absolute_error: 11.0608\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 192.33636\n",
      "Epoch 312/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 109.0765 - mean_absolute_error: 6.5651 - val_loss: 228.0189 - val_mean_absolute_error: 10.9926\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 192.33636\n",
      "Epoch 313/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 122.5205 - mean_absolute_error: 6.8426 - val_loss: 228.7863 - val_mean_absolute_error: 11.0787\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 192.33636\n",
      "Epoch 314/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 109.9395 - mean_absolute_error: 6.4537 - val_loss: 231.2536 - val_mean_absolute_error: 11.0655\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 192.33636\n",
      "Epoch 315/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 112.2619 - mean_absolute_error: 7.0347 - val_loss: 233.9480 - val_mean_absolute_error: 11.1474\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 192.33636\n",
      "Epoch 316/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 111.1199 - mean_absolute_error: 6.3969 - val_loss: 239.7676 - val_mean_absolute_error: 11.3150\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 192.33636\n",
      "Epoch 317/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 119.4102 - mean_absolute_error: 6.9630 - val_loss: 231.5288 - val_mean_absolute_error: 11.1687\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 192.33636\n",
      "Epoch 318/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 115.1373 - mean_absolute_error: 6.4587 - val_loss: 229.1347 - val_mean_absolute_error: 11.1181\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 192.33636\n",
      "Epoch 319/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 123.8047 - mean_absolute_error: 7.0119 - val_loss: 228.7159 - val_mean_absolute_error: 11.1402\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 192.33636\n",
      "Epoch 320/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 117.5723 - mean_absolute_error: 6.7208 - val_loss: 232.0037 - val_mean_absolute_error: 11.0553\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 192.33636\n",
      "Epoch 321/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 113.9372 - mean_absolute_error: 6.6934 - val_loss: 228.3387 - val_mean_absolute_error: 10.8565\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 192.33636\n",
      "Epoch 322/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 107.3009 - mean_absolute_error: 6.6139 - val_loss: 231.2887 - val_mean_absolute_error: 11.0573\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 192.33636\n",
      "Epoch 323/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 113.9267 - mean_absolute_error: 6.5176 - val_loss: 234.5522 - val_mean_absolute_error: 11.2248\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 192.33636\n",
      "Epoch 324/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 115.8596 - mean_absolute_error: 6.5596 - val_loss: 236.0273 - val_mean_absolute_error: 11.0906\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 192.33636\n",
      "Epoch 325/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 108.7239 - mean_absolute_error: 6.5936 - val_loss: 228.6282 - val_mean_absolute_error: 10.9347\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 192.33636\n",
      "Epoch 326/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 114.0177 - mean_absolute_error: 6.7974 - val_loss: 233.1241 - val_mean_absolute_error: 11.1452\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 192.33636\n",
      "Epoch 327/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 109.7244 - mean_absolute_error: 6.3474 - val_loss: 230.6091 - val_mean_absolute_error: 11.1899\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 192.33636\n",
      "Epoch 328/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 117.4401 - mean_absolute_error: 6.7952 - val_loss: 228.2790 - val_mean_absolute_error: 11.0688\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 192.33636\n",
      "Epoch 329/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 118.6366 - mean_absolute_error: 6.7267 - val_loss: 231.2100 - val_mean_absolute_error: 11.1520\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 192.33636\n",
      "Epoch 330/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 117.0727 - mean_absolute_error: 6.5739 - val_loss: 238.6989 - val_mean_absolute_error: 11.4006\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 192.33636\n",
      "Epoch 331/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 100.6058 - mean_absolute_error: 6.3112 - val_loss: 242.8853 - val_mean_absolute_error: 11.6701\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 192.33636\n",
      "Epoch 332/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 117.5585 - mean_absolute_error: 6.8320 - val_loss: 234.6568 - val_mean_absolute_error: 11.3877\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 192.33636\n",
      "Epoch 333/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 112.4753 - mean_absolute_error: 6.5914 - val_loss: 232.4020 - val_mean_absolute_error: 11.2710\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 192.33636\n",
      "Epoch 334/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 110.9652 - mean_absolute_error: 6.5759 - val_loss: 240.2890 - val_mean_absolute_error: 11.6266\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 192.33636\n",
      "Epoch 335/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 114.1905 - mean_absolute_error: 6.5825 - val_loss: 231.5615 - val_mean_absolute_error: 11.1797\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 192.33636\n",
      "Epoch 336/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 106.4749 - mean_absolute_error: 6.4148 - val_loss: 234.9663 - val_mean_absolute_error: 11.3425\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 192.33636\n",
      "Epoch 337/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 122.4042 - mean_absolute_error: 6.9212 - val_loss: 237.4314 - val_mean_absolute_error: 11.4319\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 192.33636\n",
      "Epoch 338/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 115.5355 - mean_absolute_error: 6.4374 - val_loss: 256.2260 - val_mean_absolute_error: 11.6753\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 192.33636\n",
      "Epoch 339/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 112.1786 - mean_absolute_error: 6.7041 - val_loss: 231.8753 - val_mean_absolute_error: 11.2959\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 192.33636\n",
      "Epoch 340/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 103.8350 - mean_absolute_error: 6.3001 - val_loss: 234.2923 - val_mean_absolute_error: 11.2622\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 192.33636\n",
      "Epoch 341/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 103.6159 - mean_absolute_error: 6.3064 - val_loss: 238.1906 - val_mean_absolute_error: 11.4753\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 192.33636\n",
      "Epoch 342/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 120.8737 - mean_absolute_error: 6.8378 - val_loss: 239.9508 - val_mean_absolute_error: 11.6348\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 192.33636\n",
      "Epoch 343/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 109.6969 - mean_absolute_error: 6.5031 - val_loss: 229.1098 - val_mean_absolute_error: 11.2138\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 192.33636\n",
      "Epoch 344/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 122.3258 - mean_absolute_error: 6.9380 - val_loss: 230.5147 - val_mean_absolute_error: 11.0812\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 192.33636\n",
      "Epoch 345/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 106.5666 - mean_absolute_error: 6.3806 - val_loss: 236.6061 - val_mean_absolute_error: 11.3787\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 192.33636\n",
      "Epoch 346/1000\n",
      "13/13 [==============================] - 57s 4s/step - loss: 119.0568 - mean_absolute_error: 6.7898 - val_loss: 228.7079 - val_mean_absolute_error: 11.1528\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 192.33636\n",
      "Epoch 347/1000\n",
      " 1/13 [=>............................] - ETA: 51s - loss: 82.9403 - mean_absolute_error: 5.6045"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "B_ylvp0TEsZf",
    "outputId": "2ac23eba-5e78-4f8f-c1d1-e10a17a76185"
   },
   "source": [
    "opt = keras.optimizers.Adam(learning_rate = 1e-4)\n",
    "model.compile(optimizer = opt,\n",
    "              loss='mse',\n",
    "              metrics=['mean_absolute_error'])\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
    "history = model.fit(train_X, train_Y,\n",
    "                    epochs=1000,\n",
    "                    batch_size=64,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=model_checkpoint_callback  \n",
    "                    )"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "10/10 [==============================] - 79s 6s/step - loss: 1948.0028 - mean_absolute_error: 34.5687 - val_loss: 1149.3130 - val_mean_absolute_error: 28.4367\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1149.31299, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model.hdf5\n",
      "Epoch 2/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 1233.0068 - mean_absolute_error: 29.8891 - val_loss: 944.4062 - val_mean_absolute_error: 25.3811\n",
      "\n",
      "Epoch 00002: val_loss improved from 1149.31299 to 944.40625, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model.hdf5\n",
      "Epoch 3/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 879.4665 - mean_absolute_error: 24.3914 - val_loss: 763.6973 - val_mean_absolute_error: 23.5669\n",
      "\n",
      "Epoch 00003: val_loss improved from 944.40625 to 763.69733, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model.hdf5\n",
      "Epoch 4/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 827.8016 - mean_absolute_error: 24.1032 - val_loss: 678.1772 - val_mean_absolute_error: 21.7543\n",
      "\n",
      "Epoch 00004: val_loss improved from 763.69733 to 678.17719, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model.hdf5\n",
      "Epoch 5/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 673.9480 - mean_absolute_error: 21.3997 - val_loss: 571.9401 - val_mean_absolute_error: 19.4137\n",
      "\n",
      "Epoch 00005: val_loss improved from 678.17719 to 571.94006, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model.hdf5\n",
      "Epoch 6/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 604.1864 - mean_absolute_error: 19.6163 - val_loss: 480.1984 - val_mean_absolute_error: 17.6179\n",
      "\n",
      "Epoch 00006: val_loss improved from 571.94006 to 480.19839, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model.hdf5\n",
      "Epoch 7/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 488.0161 - mean_absolute_error: 17.0420 - val_loss: 410.3144 - val_mean_absolute_error: 16.0720\n",
      "\n",
      "Epoch 00007: val_loss improved from 480.19839 to 410.31439, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model.hdf5\n",
      "Epoch 8/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 446.1280 - mean_absolute_error: 16.4121 - val_loss: 354.8183 - val_mean_absolute_error: 14.5526\n",
      "\n",
      "Epoch 00008: val_loss improved from 410.31439 to 354.81827, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model.hdf5\n",
      "Epoch 9/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 394.2836 - mean_absolute_error: 14.8361 - val_loss: 311.4628 - val_mean_absolute_error: 13.5584\n",
      "\n",
      "Epoch 00009: val_loss improved from 354.81827 to 311.46283, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model.hdf5\n",
      "Epoch 10/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 333.8113 - mean_absolute_error: 13.6588 - val_loss: 280.3321 - val_mean_absolute_error: 12.6750\n",
      "\n",
      "Epoch 00010: val_loss improved from 311.46283 to 280.33212, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model.hdf5\n",
      "Epoch 11/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 279.0218 - mean_absolute_error: 12.1019 - val_loss: 260.7858 - val_mean_absolute_error: 11.9560\n",
      "\n",
      "Epoch 00011: val_loss improved from 280.33212 to 260.78583, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model.hdf5\n",
      "Epoch 12/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 303.0222 - mean_absolute_error: 12.7593 - val_loss: 239.3331 - val_mean_absolute_error: 11.6161\n",
      "\n",
      "Epoch 00012: val_loss improved from 260.78583 to 239.33305, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model.hdf5\n",
      "Epoch 13/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 277.6201 - mean_absolute_error: 12.1955 - val_loss: 226.7831 - val_mean_absolute_error: 11.0632\n",
      "\n",
      "Epoch 00013: val_loss improved from 239.33305 to 226.78311, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model.hdf5\n",
      "Epoch 14/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 266.9450 - mean_absolute_error: 11.6330 - val_loss: 215.7790 - val_mean_absolute_error: 10.5710\n",
      "\n",
      "Epoch 00014: val_loss improved from 226.78311 to 215.77902, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model.hdf5\n",
      "Epoch 15/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 264.9605 - mean_absolute_error: 11.6049 - val_loss: 222.4369 - val_mean_absolute_error: 11.0118\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 215.77902\n",
      "Epoch 16/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 250.1060 - mean_absolute_error: 11.3590 - val_loss: 209.5649 - val_mean_absolute_error: 10.4561\n",
      "\n",
      "Epoch 00016: val_loss improved from 215.77902 to 209.56491, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model.hdf5\n",
      "Epoch 17/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 238.6353 - mean_absolute_error: 10.8380 - val_loss: 208.9222 - val_mean_absolute_error: 10.3821\n",
      "\n",
      "Epoch 00017: val_loss improved from 209.56491 to 208.92221, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model.hdf5\n",
      "Epoch 18/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 219.4167 - mean_absolute_error: 10.5681 - val_loss: 204.2667 - val_mean_absolute_error: 10.2454\n",
      "\n",
      "Epoch 00018: val_loss improved from 208.92221 to 204.26669, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model.hdf5\n",
      "Epoch 19/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 238.2270 - mean_absolute_error: 10.9202 - val_loss: 203.7191 - val_mean_absolute_error: 10.2431\n",
      "\n",
      "Epoch 00019: val_loss improved from 204.26669 to 203.71909, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model.hdf5\n",
      "Epoch 20/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 212.3010 - mean_absolute_error: 10.5019 - val_loss: 202.6419 - val_mean_absolute_error: 10.2175\n",
      "\n",
      "Epoch 00020: val_loss improved from 203.71909 to 202.64189, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model.hdf5\n",
      "Epoch 21/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 221.3558 - mean_absolute_error: 10.5271 - val_loss: 201.2519 - val_mean_absolute_error: 10.2129\n",
      "\n",
      "Epoch 00021: val_loss improved from 202.64189 to 201.25191, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model.hdf5\n",
      "Epoch 22/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 201.7284 - mean_absolute_error: 9.7142 - val_loss: 202.4743 - val_mean_absolute_error: 10.2742\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 201.25191\n",
      "Epoch 23/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 190.0405 - mean_absolute_error: 9.8530 - val_loss: 200.2085 - val_mean_absolute_error: 10.1462\n",
      "\n",
      "Epoch 00023: val_loss improved from 201.25191 to 200.20848, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model.hdf5\n",
      "Epoch 24/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 202.2989 - mean_absolute_error: 10.2150 - val_loss: 200.4393 - val_mean_absolute_error: 10.1706\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 200.20848\n",
      "Epoch 25/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 223.4334 - mean_absolute_error: 10.7812 - val_loss: 206.2264 - val_mean_absolute_error: 10.3173\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 200.20848\n",
      "Epoch 26/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 212.3973 - mean_absolute_error: 9.9799 - val_loss: 201.1352 - val_mean_absolute_error: 10.2431\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 200.20848\n",
      "Epoch 27/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 179.1913 - mean_absolute_error: 9.4567 - val_loss: 203.6645 - val_mean_absolute_error: 10.3655\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 200.20848\n",
      "Epoch 28/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 221.8338 - mean_absolute_error: 10.4129 - val_loss: 207.8145 - val_mean_absolute_error: 10.5567\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 200.20848\n",
      "Epoch 29/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 199.4623 - mean_absolute_error: 10.2106 - val_loss: 199.9796 - val_mean_absolute_error: 10.2229\n",
      "\n",
      "Epoch 00029: val_loss improved from 200.20848 to 199.97957, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model.hdf5\n",
      "Epoch 30/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 186.0973 - mean_absolute_error: 9.6887 - val_loss: 199.8197 - val_mean_absolute_error: 10.2090\n",
      "\n",
      "Epoch 00030: val_loss improved from 199.97957 to 199.81967, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model.hdf5\n",
      "Epoch 31/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 180.6863 - mean_absolute_error: 9.4342 - val_loss: 201.3849 - val_mean_absolute_error: 10.2413\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 199.81967\n",
      "Epoch 32/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 202.7201 - mean_absolute_error: 10.0356 - val_loss: 199.1230 - val_mean_absolute_error: 10.1575\n",
      "\n",
      "Epoch 00032: val_loss improved from 199.81967 to 199.12296, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model.hdf5\n",
      "Epoch 33/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 185.1167 - mean_absolute_error: 9.4087 - val_loss: 196.6918 - val_mean_absolute_error: 10.1770\n",
      "\n",
      "Epoch 00033: val_loss improved from 199.12296 to 196.69179, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model.hdf5\n",
      "Epoch 34/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 188.8923 - mean_absolute_error: 9.5212 - val_loss: 207.9657 - val_mean_absolute_error: 10.6392\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 196.69179\n",
      "Epoch 35/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 198.4506 - mean_absolute_error: 10.0488 - val_loss: 193.1818 - val_mean_absolute_error: 10.0093\n",
      "\n",
      "Epoch 00035: val_loss improved from 196.69179 to 193.18184, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model.hdf5\n",
      "Epoch 36/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 202.5415 - mean_absolute_error: 10.0294 - val_loss: 196.3248 - val_mean_absolute_error: 10.1212\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 193.18184\n",
      "Epoch 37/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 192.4059 - mean_absolute_error: 9.9379 - val_loss: 201.0753 - val_mean_absolute_error: 10.2596\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 193.18184\n",
      "Epoch 38/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 182.6529 - mean_absolute_error: 9.4854 - val_loss: 205.3963 - val_mean_absolute_error: 10.6002\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 193.18184\n",
      "Epoch 39/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 190.3191 - mean_absolute_error: 9.8785 - val_loss: 193.8693 - val_mean_absolute_error: 10.0327\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 193.18184\n",
      "Epoch 40/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 183.7687 - mean_absolute_error: 9.5569 - val_loss: 192.2897 - val_mean_absolute_error: 9.9289\n",
      "\n",
      "Epoch 00040: val_loss improved from 193.18184 to 192.28967, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model.hdf5\n",
      "Epoch 41/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 160.9125 - mean_absolute_error: 8.8478 - val_loss: 200.6825 - val_mean_absolute_error: 10.0931\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 192.28967\n",
      "Epoch 42/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 189.7519 - mean_absolute_error: 9.7948 - val_loss: 194.8265 - val_mean_absolute_error: 10.0722\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 192.28967\n",
      "Epoch 43/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 188.5098 - mean_absolute_error: 9.6811 - val_loss: 199.9498 - val_mean_absolute_error: 10.1698\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 192.28967\n",
      "Epoch 44/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 191.3177 - mean_absolute_error: 9.7866 - val_loss: 198.2199 - val_mean_absolute_error: 10.0945\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 192.28967\n",
      "Epoch 45/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 173.2847 - mean_absolute_error: 9.3534 - val_loss: 197.5767 - val_mean_absolute_error: 10.0491\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 192.28967\n",
      "Epoch 46/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 181.2941 - mean_absolute_error: 9.3585 - val_loss: 195.1000 - val_mean_absolute_error: 9.9753\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 192.28967\n",
      "Epoch 47/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 177.6397 - mean_absolute_error: 9.4679 - val_loss: 193.6119 - val_mean_absolute_error: 9.9475\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 192.28967\n",
      "Epoch 48/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 185.9407 - mean_absolute_error: 9.7616 - val_loss: 200.2301 - val_mean_absolute_error: 10.2443\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 192.28967\n",
      "Epoch 49/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 175.5709 - mean_absolute_error: 9.4510 - val_loss: 200.2740 - val_mean_absolute_error: 10.1755\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 192.28967\n",
      "Epoch 50/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 160.1833 - mean_absolute_error: 8.9371 - val_loss: 196.3976 - val_mean_absolute_error: 9.9471\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 192.28967\n",
      "Epoch 51/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 174.1062 - mean_absolute_error: 9.3272 - val_loss: 191.9862 - val_mean_absolute_error: 9.8913\n",
      "\n",
      "Epoch 00051: val_loss improved from 192.28967 to 191.98621, saving model to /content/drive/My Drive/Colab Notebooks/DACCO/best_cnn_model.hdf5\n",
      "Epoch 52/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 164.5069 - mean_absolute_error: 8.9908 - val_loss: 205.6624 - val_mean_absolute_error: 10.2097\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 191.98621\n",
      "Epoch 53/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 168.4475 - mean_absolute_error: 9.1053 - val_loss: 201.9382 - val_mean_absolute_error: 10.0608\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 191.98621\n",
      "Epoch 54/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 175.7987 - mean_absolute_error: 9.7045 - val_loss: 197.7816 - val_mean_absolute_error: 9.9547\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 191.98621\n",
      "Epoch 55/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 175.7242 - mean_absolute_error: 9.4171 - val_loss: 211.9471 - val_mean_absolute_error: 10.4361\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 191.98621\n",
      "Epoch 56/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 181.4374 - mean_absolute_error: 9.5086 - val_loss: 206.5368 - val_mean_absolute_error: 10.3956\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 191.98621\n",
      "Epoch 57/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 165.8376 - mean_absolute_error: 9.0559 - val_loss: 196.4913 - val_mean_absolute_error: 10.0120\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 191.98621\n",
      "Epoch 58/1000\n",
      " 9/10 [==========================>...] - ETA: 5s - loss: 171.7966 - mean_absolute_error: 9.1715 "
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "naL6TuAmcwFt",
    "executionInfo": {
     "elapsed": 19452146,
     "status": "error",
     "timestamp": 1626098644087,
     "user": {
      "displayName": "Zahra Sadeghi",
      "photoUrl": "",
      "userId": "17928363754993821426"
     },
     "user_tz": -120
    },
    "outputId": "235d6522-3b71-4884-fced-7f2276e0ecc8"
   },
   "source": [
    "opt = keras.optimizers.Adam(learning_rate = 1e-4)\n",
    "model.compile(optimizer = opt,\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mae'])\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
    "history = model.fit(train_X, train_Y,\n",
    "                    epochs=1000,\n",
    "                    batch_size=64,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=model_checkpoint_callback  \n",
    "                    )"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "10/10 [==============================] - 73s 6s/step - loss: 1734.7352 - mae: 32.8010 - val_loss: 1163.1273 - val_mae: 28.5813\n",
      "Epoch 2/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 1197.5088 - mae: 29.4028 - val_loss: 891.9045 - val_mae: 24.8216\n",
      "Epoch 3/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 920.1581 - mae: 24.7995 - val_loss: 748.5442 - val_mae: 22.9498\n",
      "Epoch 4/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 761.5400 - mae: 22.9081 - val_loss: 676.3766 - val_mae: 21.5409\n",
      "Epoch 5/1000\n",
      "10/10 [==============================] - 55s 6s/step - loss: 643.2063 - mae: 20.2943 - val_loss: 620.0079 - val_mae: 20.1023\n",
      "Epoch 6/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 673.5240 - mae: 20.8485 - val_loss: 529.1867 - val_mae: 18.4418\n",
      "Epoch 7/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 566.3809 - mae: 18.8748 - val_loss: 468.8873 - val_mae: 17.4023\n",
      "Epoch 8/1000\n",
      "10/10 [==============================] - 58s 6s/step - loss: 461.5191 - mae: 16.5437 - val_loss: 406.3470 - val_mae: 16.0818\n",
      "Epoch 9/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 429.0770 - mae: 15.6162 - val_loss: 358.7212 - val_mae: 14.7656\n",
      "Epoch 10/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 362.5483 - mae: 14.2817 - val_loss: 317.2308 - val_mae: 13.6409\n",
      "Epoch 11/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 338.7370 - mae: 13.6004 - val_loss: 283.2918 - val_mae: 12.6280\n",
      "Epoch 12/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 302.2007 - mae: 12.9395 - val_loss: 261.0279 - val_mae: 11.9409\n",
      "Epoch 13/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 268.8060 - mae: 11.8820 - val_loss: 236.7755 - val_mae: 11.2537\n",
      "Epoch 14/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 257.4880 - mae: 11.4673 - val_loss: 227.8917 - val_mae: 11.2143\n",
      "Epoch 15/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 262.7780 - mae: 11.5607 - val_loss: 223.7338 - val_mae: 10.7519\n",
      "Epoch 16/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 240.8346 - mae: 11.1555 - val_loss: 216.9892 - val_mae: 10.5905\n",
      "Epoch 17/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 225.5817 - mae: 10.3529 - val_loss: 215.0594 - val_mae: 10.6578\n",
      "Epoch 18/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 223.9978 - mae: 10.5911 - val_loss: 210.5844 - val_mae: 10.4664\n",
      "Epoch 19/1000\n",
      "10/10 [==============================] - 58s 6s/step - loss: 233.2545 - mae: 10.7794 - val_loss: 214.5151 - val_mae: 10.6999\n",
      "Epoch 20/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 238.9345 - mae: 11.1125 - val_loss: 206.0649 - val_mae: 10.3390\n",
      "Epoch 21/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 217.0506 - mae: 10.3776 - val_loss: 204.6346 - val_mae: 10.2810\n",
      "Epoch 22/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 228.2640 - mae: 10.5274 - val_loss: 207.6204 - val_mae: 10.4269\n",
      "Epoch 23/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 229.8672 - mae: 10.9118 - val_loss: 212.5980 - val_mae: 10.6143\n",
      "Epoch 24/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 217.6613 - mae: 10.3412 - val_loss: 203.5772 - val_mae: 10.3289\n",
      "Epoch 25/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 225.9428 - mae: 10.6386 - val_loss: 204.8049 - val_mae: 10.4567\n",
      "Epoch 26/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 213.4415 - mae: 10.2045 - val_loss: 197.2421 - val_mae: 10.2101\n",
      "Epoch 27/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 212.9549 - mae: 10.1864 - val_loss: 216.3391 - val_mae: 10.5709\n",
      "Epoch 28/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 233.1182 - mae: 10.7053 - val_loss: 197.7504 - val_mae: 10.1550\n",
      "Epoch 29/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 212.3490 - mae: 10.1959 - val_loss: 197.9973 - val_mae: 10.1665\n",
      "Epoch 30/1000\n",
      "10/10 [==============================] - 58s 6s/step - loss: 215.7518 - mae: 10.3503 - val_loss: 197.3782 - val_mae: 10.1205\n",
      "Epoch 31/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 200.8669 - mae: 10.1313 - val_loss: 201.8940 - val_mae: 10.2614\n",
      "Epoch 32/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 210.2698 - mae: 10.3414 - val_loss: 204.0108 - val_mae: 10.4772\n",
      "Epoch 33/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 214.4997 - mae: 10.6148 - val_loss: 204.0234 - val_mae: 10.4531\n",
      "Epoch 34/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 212.9498 - mae: 10.1059 - val_loss: 205.2315 - val_mae: 10.3253\n",
      "Epoch 35/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 212.8427 - mae: 10.7851 - val_loss: 202.7277 - val_mae: 10.2075\n",
      "Epoch 36/1000\n",
      "10/10 [==============================] - 57s 6s/step - loss: 205.0002 - mae: 10.1655 - val_loss: 201.2766 - val_mae: 10.1927\n",
      "Epoch 37/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 193.0140 - mae: 9.8579 - val_loss: 200.4589 - val_mae: 10.1453\n",
      "Epoch 38/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 187.5606 - mae: 9.6514 - val_loss: 195.3007 - val_mae: 9.9854\n",
      "Epoch 39/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 177.6848 - mae: 9.5253 - val_loss: 189.0959 - val_mae: 9.7355\n",
      "Epoch 40/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 193.0763 - mae: 9.8438 - val_loss: 196.4987 - val_mae: 10.1196\n",
      "Epoch 41/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 206.7261 - mae: 10.0879 - val_loss: 194.1381 - val_mae: 9.9331\n",
      "Epoch 42/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 197.0358 - mae: 9.9584 - val_loss: 193.6454 - val_mae: 9.8697\n",
      "Epoch 43/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 192.9452 - mae: 9.7461 - val_loss: 189.9546 - val_mae: 9.8357\n",
      "Epoch 44/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 185.4339 - mae: 9.5608 - val_loss: 192.7624 - val_mae: 9.9415\n",
      "Epoch 45/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 185.6609 - mae: 9.6432 - val_loss: 194.7100 - val_mae: 9.9829\n",
      "Epoch 46/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 184.7146 - mae: 9.6591 - val_loss: 192.0482 - val_mae: 9.9995\n",
      "Epoch 47/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 177.8823 - mae: 9.4558 - val_loss: 193.3438 - val_mae: 10.0056\n",
      "Epoch 48/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 181.2665 - mae: 9.5988 - val_loss: 197.8976 - val_mae: 10.2483\n",
      "Epoch 49/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 181.2045 - mae: 9.3945 - val_loss: 194.2817 - val_mae: 9.9981\n",
      "Epoch 50/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 179.8552 - mae: 9.5281 - val_loss: 196.2153 - val_mae: 9.9880\n",
      "Epoch 51/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 177.1322 - mae: 9.1064 - val_loss: 204.3537 - val_mae: 10.3987\n",
      "Epoch 52/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 182.2653 - mae: 9.3915 - val_loss: 213.0507 - val_mae: 10.4095\n",
      "Epoch 53/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 182.1851 - mae: 9.3537 - val_loss: 205.1784 - val_mae: 10.2599\n",
      "Epoch 54/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 161.6792 - mae: 9.0286 - val_loss: 208.1573 - val_mae: 10.3258\n",
      "Epoch 55/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 180.0419 - mae: 9.4433 - val_loss: 202.9101 - val_mae: 10.1374\n",
      "Epoch 56/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 183.2317 - mae: 9.5485 - val_loss: 192.7813 - val_mae: 9.8133\n",
      "Epoch 57/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 184.6394 - mae: 9.6154 - val_loss: 196.2695 - val_mae: 10.0131\n",
      "Epoch 58/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 159.2221 - mae: 8.9169 - val_loss: 191.4247 - val_mae: 9.8377\n",
      "Epoch 59/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 182.6725 - mae: 9.5571 - val_loss: 195.7166 - val_mae: 9.7914\n",
      "Epoch 60/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 181.3685 - mae: 9.6411 - val_loss: 229.4373 - val_mae: 10.8602\n",
      "Epoch 61/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 181.7774 - mae: 9.5801 - val_loss: 211.4543 - val_mae: 10.3626\n",
      "Epoch 62/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 168.5591 - mae: 8.9982 - val_loss: 194.8308 - val_mae: 9.9184\n",
      "Epoch 63/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 157.5621 - mae: 8.9652 - val_loss: 197.1778 - val_mae: 9.8783\n",
      "Epoch 64/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 160.0069 - mae: 8.6867 - val_loss: 195.7248 - val_mae: 9.9704\n",
      "Epoch 65/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 171.9743 - mae: 9.0372 - val_loss: 197.8665 - val_mae: 9.9461\n",
      "Epoch 66/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 176.7791 - mae: 9.2978 - val_loss: 199.6413 - val_mae: 9.9160\n",
      "Epoch 67/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 174.4248 - mae: 9.0427 - val_loss: 206.1037 - val_mae: 10.1827\n",
      "Epoch 68/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 173.7790 - mae: 9.1107 - val_loss: 210.2405 - val_mae: 10.2883\n",
      "Epoch 69/1000\n",
      "10/10 [==============================] - 60s 6s/step - loss: 183.8119 - mae: 9.2941 - val_loss: 197.5742 - val_mae: 10.0616\n",
      "Epoch 70/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 189.0454 - mae: 9.9273 - val_loss: 203.4639 - val_mae: 10.3223\n",
      "Epoch 71/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 173.1690 - mae: 9.0417 - val_loss: 200.2974 - val_mae: 10.0061\n",
      "Epoch 72/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 198.9981 - mae: 9.8222 - val_loss: 194.9406 - val_mae: 9.8748\n",
      "Epoch 73/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 172.1889 - mae: 9.0540 - val_loss: 192.5602 - val_mae: 9.7110\n",
      "Epoch 74/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 159.9677 - mae: 8.7809 - val_loss: 199.4955 - val_mae: 9.9013\n",
      "Epoch 75/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 167.4854 - mae: 9.0087 - val_loss: 205.1551 - val_mae: 9.9553\n",
      "Epoch 76/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 172.9282 - mae: 9.2902 - val_loss: 205.7868 - val_mae: 10.0096\n",
      "Epoch 77/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 156.6067 - mae: 8.4386 - val_loss: 206.3520 - val_mae: 10.2349\n",
      "Epoch 78/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 164.5382 - mae: 8.9253 - val_loss: 198.1448 - val_mae: 9.8788\n",
      "Epoch 79/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 166.7955 - mae: 8.9078 - val_loss: 191.2910 - val_mae: 9.6802\n",
      "Epoch 80/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 177.4682 - mae: 9.2913 - val_loss: 197.7079 - val_mae: 9.7418\n",
      "Epoch 81/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 176.1275 - mae: 9.5673 - val_loss: 209.8642 - val_mae: 10.2265\n",
      "Epoch 82/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 172.8129 - mae: 9.0476 - val_loss: 214.5603 - val_mae: 10.3944\n",
      "Epoch 83/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 165.3477 - mae: 8.7415 - val_loss: 233.6057 - val_mae: 10.9386\n",
      "Epoch 84/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 180.7570 - mae: 9.2664 - val_loss: 209.9515 - val_mae: 10.1970\n",
      "Epoch 85/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 170.9719 - mae: 8.8822 - val_loss: 204.2161 - val_mae: 10.2451\n",
      "Epoch 86/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 159.6451 - mae: 8.7571 - val_loss: 197.8255 - val_mae: 9.9924\n",
      "Epoch 87/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 146.8457 - mae: 8.2122 - val_loss: 195.1661 - val_mae: 9.7842\n",
      "Epoch 88/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 168.4576 - mae: 9.1143 - val_loss: 200.8854 - val_mae: 10.0429\n",
      "Epoch 89/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 151.9041 - mae: 8.7177 - val_loss: 217.6972 - val_mae: 10.3808\n",
      "Epoch 90/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 158.7708 - mae: 8.8138 - val_loss: 209.4900 - val_mae: 10.1224\n",
      "Epoch 91/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 156.9694 - mae: 8.6536 - val_loss: 194.7934 - val_mae: 9.7069\n",
      "Epoch 92/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 150.4737 - mae: 8.5651 - val_loss: 199.7190 - val_mae: 9.9609\n",
      "Epoch 93/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 147.7306 - mae: 8.3723 - val_loss: 202.5511 - val_mae: 9.9897\n",
      "Epoch 94/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 152.2891 - mae: 8.5492 - val_loss: 194.8486 - val_mae: 9.7403\n",
      "Epoch 95/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 168.8484 - mae: 9.0761 - val_loss: 190.2323 - val_mae: 9.6322\n",
      "Epoch 96/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 141.9242 - mae: 8.0815 - val_loss: 192.3829 - val_mae: 9.7915\n",
      "Epoch 97/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 144.7841 - mae: 8.2360 - val_loss: 190.9551 - val_mae: 9.8447\n",
      "Epoch 98/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 149.7967 - mae: 8.2428 - val_loss: 211.7298 - val_mae: 10.5096\n",
      "Epoch 99/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 165.7483 - mae: 8.8528 - val_loss: 202.5920 - val_mae: 10.2653\n",
      "Epoch 100/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 177.7561 - mae: 9.1809 - val_loss: 194.3535 - val_mae: 9.9902\n",
      "Epoch 101/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 171.6053 - mae: 9.3329 - val_loss: 199.1009 - val_mae: 10.1759\n",
      "Epoch 102/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 155.9439 - mae: 8.5105 - val_loss: 200.0981 - val_mae: 10.1227\n",
      "Epoch 103/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 166.2076 - mae: 9.0404 - val_loss: 200.6405 - val_mae: 10.0569\n",
      "Epoch 104/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 154.2462 - mae: 8.7953 - val_loss: 197.9568 - val_mae: 9.9604\n",
      "Epoch 105/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 163.9140 - mae: 8.8055 - val_loss: 194.5353 - val_mae: 9.8587\n",
      "Epoch 106/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 155.9406 - mae: 8.5780 - val_loss: 197.3433 - val_mae: 9.9796\n",
      "Epoch 107/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 159.1302 - mae: 8.7738 - val_loss: 199.7761 - val_mae: 10.0658\n",
      "Epoch 108/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 156.0606 - mae: 8.4969 - val_loss: 197.8481 - val_mae: 10.0304\n",
      "Epoch 109/1000\n",
      "10/10 [==============================] - 63s 6s/step - loss: 147.3025 - mae: 8.3192 - val_loss: 192.2088 - val_mae: 9.6419\n",
      "Epoch 110/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 156.3979 - mae: 8.4508 - val_loss: 197.9402 - val_mae: 9.8748\n",
      "Epoch 111/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 164.2438 - mae: 8.8417 - val_loss: 200.1378 - val_mae: 9.9522\n",
      "Epoch 112/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 151.0538 - mae: 8.1357 - val_loss: 194.1374 - val_mae: 9.7204\n",
      "Epoch 113/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 163.2779 - mae: 8.9205 - val_loss: 199.7572 - val_mae: 9.9712\n",
      "Epoch 114/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 149.9770 - mae: 8.2980 - val_loss: 184.5671 - val_mae: 9.4076\n",
      "Epoch 115/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 151.0093 - mae: 8.5708 - val_loss: 185.4916 - val_mae: 9.2706\n",
      "Epoch 116/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 138.7519 - mae: 8.1176 - val_loss: 187.2823 - val_mae: 9.3641\n",
      "Epoch 117/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 138.5490 - mae: 8.0249 - val_loss: 200.0211 - val_mae: 9.9853\n",
      "Epoch 118/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 157.4917 - mae: 8.6944 - val_loss: 196.5756 - val_mae: 9.7518\n",
      "Epoch 119/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 150.3541 - mae: 8.2438 - val_loss: 190.5047 - val_mae: 9.5676\n",
      "Epoch 120/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 141.5430 - mae: 8.0860 - val_loss: 196.0443 - val_mae: 9.8063\n",
      "Epoch 121/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 147.0380 - mae: 8.2868 - val_loss: 203.4314 - val_mae: 9.9987\n",
      "Epoch 122/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 141.4955 - mae: 8.0801 - val_loss: 200.7284 - val_mae: 10.0133\n",
      "Epoch 123/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 153.3501 - mae: 8.3447 - val_loss: 195.8425 - val_mae: 9.7134\n",
      "Epoch 124/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 141.8549 - mae: 8.2522 - val_loss: 197.5192 - val_mae: 9.9526\n",
      "Epoch 125/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 128.7892 - mae: 7.7907 - val_loss: 198.7079 - val_mae: 9.8972\n",
      "Epoch 126/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 133.4182 - mae: 7.8984 - val_loss: 194.2642 - val_mae: 9.7336\n",
      "Epoch 127/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 132.6634 - mae: 7.8186 - val_loss: 202.3756 - val_mae: 9.9597\n",
      "Epoch 128/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 154.3469 - mae: 8.5508 - val_loss: 203.8245 - val_mae: 10.1029\n",
      "Epoch 129/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 158.6659 - mae: 8.6543 - val_loss: 206.2428 - val_mae: 10.1410\n",
      "Epoch 130/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 135.2661 - mae: 7.9123 - val_loss: 207.8909 - val_mae: 10.2054\n",
      "Epoch 131/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 149.3682 - mae: 8.3948 - val_loss: 204.0434 - val_mae: 10.0106\n",
      "Epoch 132/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 154.6613 - mae: 8.4093 - val_loss: 200.3207 - val_mae: 9.8089\n",
      "Epoch 133/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 137.4580 - mae: 7.9951 - val_loss: 190.2140 - val_mae: 9.5163\n",
      "Epoch 134/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 142.1350 - mae: 8.1398 - val_loss: 199.2498 - val_mae: 9.9396\n",
      "Epoch 135/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 153.7895 - mae: 8.5422 - val_loss: 203.3370 - val_mae: 10.0623\n",
      "Epoch 136/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 140.4202 - mae: 7.8913 - val_loss: 197.9928 - val_mae: 9.7291\n",
      "Epoch 137/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 168.7266 - mae: 8.9709 - val_loss: 198.6966 - val_mae: 9.8413\n",
      "Epoch 138/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 134.7365 - mae: 7.8812 - val_loss: 190.9516 - val_mae: 9.6174\n",
      "Epoch 139/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 131.8614 - mae: 7.7733 - val_loss: 189.7431 - val_mae: 9.5105\n",
      "Epoch 140/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 161.0523 - mae: 8.6680 - val_loss: 201.5583 - val_mae: 10.1073\n",
      "Epoch 141/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 149.4442 - mae: 8.2455 - val_loss: 208.1819 - val_mae: 10.3581\n",
      "Epoch 142/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 164.4794 - mae: 9.1152 - val_loss: 204.9097 - val_mae: 10.1492\n",
      "Epoch 143/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 172.4559 - mae: 9.1484 - val_loss: 191.1553 - val_mae: 9.5463\n",
      "Epoch 144/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 132.8640 - mae: 7.7586 - val_loss: 199.6275 - val_mae: 9.9084\n",
      "Epoch 145/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 135.8050 - mae: 7.8180 - val_loss: 194.9632 - val_mae: 9.7758\n",
      "Epoch 146/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 134.7053 - mae: 7.9023 - val_loss: 196.9122 - val_mae: 9.8524\n",
      "Epoch 147/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 135.3001 - mae: 7.8606 - val_loss: 197.5423 - val_mae: 9.7663\n",
      "Epoch 148/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 136.5566 - mae: 8.0327 - val_loss: 196.3822 - val_mae: 9.7333\n",
      "Epoch 149/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 129.9979 - mae: 7.7886 - val_loss: 198.6715 - val_mae: 9.9202\n",
      "Epoch 150/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 145.8678 - mae: 8.1497 - val_loss: 202.0608 - val_mae: 9.9334\n",
      "Epoch 151/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 148.6047 - mae: 7.9825 - val_loss: 206.9981 - val_mae: 10.0533\n",
      "Epoch 152/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 145.9781 - mae: 8.2511 - val_loss: 204.1262 - val_mae: 9.9715\n",
      "Epoch 153/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 144.9112 - mae: 8.2187 - val_loss: 222.0044 - val_mae: 10.5015\n",
      "Epoch 154/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 154.2265 - mae: 8.6542 - val_loss: 198.2379 - val_mae: 9.9129\n",
      "Epoch 155/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 141.2808 - mae: 8.1140 - val_loss: 194.7526 - val_mae: 9.8073\n",
      "Epoch 156/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 135.0335 - mae: 7.9100 - val_loss: 207.5614 - val_mae: 10.1295\n",
      "Epoch 157/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 147.1788 - mae: 8.3785 - val_loss: 197.4252 - val_mae: 9.8229\n",
      "Epoch 158/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 150.7787 - mae: 8.3264 - val_loss: 200.2192 - val_mae: 9.9570\n",
      "Epoch 159/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 141.0317 - mae: 8.0003 - val_loss: 201.2790 - val_mae: 9.9771\n",
      "Epoch 160/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 150.7002 - mae: 8.1515 - val_loss: 202.9589 - val_mae: 10.0117\n",
      "Epoch 161/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 150.4183 - mae: 8.0993 - val_loss: 209.2109 - val_mae: 10.3211\n",
      "Epoch 162/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 134.6203 - mae: 7.6169 - val_loss: 201.8274 - val_mae: 10.0426\n",
      "Epoch 163/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 129.9865 - mae: 7.7805 - val_loss: 201.6093 - val_mae: 9.9580\n",
      "Epoch 164/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 151.0930 - mae: 8.4851 - val_loss: 212.9907 - val_mae: 10.3196\n",
      "Epoch 165/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 134.8403 - mae: 7.7226 - val_loss: 202.4279 - val_mae: 9.8997\n",
      "Epoch 166/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 152.4957 - mae: 8.3537 - val_loss: 196.2128 - val_mae: 9.6995\n",
      "Epoch 167/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 125.5525 - mae: 7.5451 - val_loss: 194.2861 - val_mae: 9.8334\n",
      "Epoch 168/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 137.4740 - mae: 7.9529 - val_loss: 206.4549 - val_mae: 10.2739\n",
      "Epoch 169/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 147.1110 - mae: 8.0991 - val_loss: 195.6194 - val_mae: 9.6124\n",
      "Epoch 170/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 149.6898 - mae: 8.3887 - val_loss: 196.9458 - val_mae: 9.8032\n",
      "Epoch 171/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 152.5178 - mae: 8.5364 - val_loss: 198.8931 - val_mae: 10.0100\n",
      "Epoch 172/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 140.0505 - mae: 7.9675 - val_loss: 198.0938 - val_mae: 9.9667\n",
      "Epoch 173/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 139.4776 - mae: 8.1248 - val_loss: 193.7262 - val_mae: 9.7068\n",
      "Epoch 174/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 133.1826 - mae: 7.7833 - val_loss: 201.0260 - val_mae: 9.7550\n",
      "Epoch 175/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 149.8292 - mae: 8.0502 - val_loss: 199.3614 - val_mae: 9.8789\n",
      "Epoch 176/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 142.1028 - mae: 8.0438 - val_loss: 198.4774 - val_mae: 9.9642\n",
      "Epoch 177/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 165.9368 - mae: 8.7782 - val_loss: 227.2370 - val_mae: 11.0033\n",
      "Epoch 178/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 135.5065 - mae: 8.0257 - val_loss: 207.7401 - val_mae: 10.2352\n",
      "Epoch 179/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 138.4818 - mae: 7.9916 - val_loss: 195.2568 - val_mae: 9.8912\n",
      "Epoch 180/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 123.0164 - mae: 7.3231 - val_loss: 194.8003 - val_mae: 9.7838\n",
      "Epoch 181/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 137.7923 - mae: 7.9867 - val_loss: 191.1339 - val_mae: 9.6728\n",
      "Epoch 182/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 136.5778 - mae: 7.8642 - val_loss: 190.0232 - val_mae: 9.5311\n",
      "Epoch 183/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 126.7383 - mae: 7.5871 - val_loss: 199.5615 - val_mae: 9.8203\n",
      "Epoch 184/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 135.7027 - mae: 7.7419 - val_loss: 197.6220 - val_mae: 9.7913\n",
      "Epoch 185/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 144.8978 - mae: 8.1747 - val_loss: 198.8399 - val_mae: 9.9191\n",
      "Epoch 186/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 122.4934 - mae: 7.2696 - val_loss: 192.8305 - val_mae: 9.4465\n",
      "Epoch 187/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 142.9275 - mae: 8.1948 - val_loss: 191.4183 - val_mae: 9.4276\n",
      "Epoch 188/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 113.4709 - mae: 6.8212 - val_loss: 219.6793 - val_mae: 10.6288\n",
      "Epoch 189/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 137.4895 - mae: 7.8512 - val_loss: 200.0958 - val_mae: 9.9202\n",
      "Epoch 190/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 128.7488 - mae: 7.5886 - val_loss: 200.7523 - val_mae: 10.0432\n",
      "Epoch 191/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 134.4825 - mae: 7.7400 - val_loss: 198.4956 - val_mae: 9.9272\n",
      "Epoch 192/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 135.6900 - mae: 7.5328 - val_loss: 195.6892 - val_mae: 9.8557\n",
      "Epoch 193/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 138.9420 - mae: 7.9203 - val_loss: 197.7803 - val_mae: 9.9298\n",
      "Epoch 194/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 124.2179 - mae: 7.2822 - val_loss: 197.3233 - val_mae: 9.9283\n",
      "Epoch 195/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 124.0453 - mae: 7.2861 - val_loss: 197.4108 - val_mae: 9.8682\n",
      "Epoch 196/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 140.4994 - mae: 8.0116 - val_loss: 191.8094 - val_mae: 9.6930\n",
      "Epoch 197/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 141.3388 - mae: 8.0620 - val_loss: 192.3613 - val_mae: 9.6997\n",
      "Epoch 198/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 140.1004 - mae: 8.0078 - val_loss: 197.2323 - val_mae: 9.8857\n",
      "Epoch 199/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 144.1349 - mae: 7.9870 - val_loss: 206.1492 - val_mae: 10.2801\n",
      "Epoch 200/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 120.5915 - mae: 7.2495 - val_loss: 193.5490 - val_mae: 9.7750\n",
      "Epoch 201/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 130.4140 - mae: 7.5794 - val_loss: 192.4270 - val_mae: 9.8112\n",
      "Epoch 202/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 127.0867 - mae: 7.4733 - val_loss: 200.0925 - val_mae: 9.8788\n",
      "Epoch 203/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 130.8257 - mae: 7.7644 - val_loss: 197.9792 - val_mae: 9.7716\n",
      "Epoch 204/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 154.7518 - mae: 8.4701 - val_loss: 203.5957 - val_mae: 10.0201\n",
      "Epoch 205/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 153.2980 - mae: 8.6640 - val_loss: 210.2936 - val_mae: 10.3843\n",
      "Epoch 206/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 136.9786 - mae: 7.9111 - val_loss: 222.5813 - val_mae: 10.8444\n",
      "Epoch 207/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 142.5900 - mae: 8.1043 - val_loss: 208.0470 - val_mae: 10.3420\n",
      "Epoch 208/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 130.6234 - mae: 7.6862 - val_loss: 193.6074 - val_mae: 9.7388\n",
      "Epoch 209/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 134.9896 - mae: 8.0433 - val_loss: 182.2202 - val_mae: 9.3996\n",
      "Epoch 210/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 137.0962 - mae: 7.7558 - val_loss: 194.8416 - val_mae: 9.9091\n",
      "Epoch 211/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 138.3795 - mae: 7.8500 - val_loss: 198.9085 - val_mae: 10.0838\n",
      "Epoch 212/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 140.0112 - mae: 7.8518 - val_loss: 194.4901 - val_mae: 9.8374\n",
      "Epoch 213/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 150.2554 - mae: 8.1188 - val_loss: 195.1206 - val_mae: 9.8379\n",
      "Epoch 214/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 130.8030 - mae: 7.5636 - val_loss: 195.4614 - val_mae: 9.8869\n",
      "Epoch 215/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 124.5971 - mae: 7.3559 - val_loss: 187.1217 - val_mae: 9.3840\n",
      "Epoch 216/1000\n",
      "10/10 [==============================] - 63s 6s/step - loss: 131.4461 - mae: 7.5894 - val_loss: 193.3625 - val_mae: 9.6299\n",
      "Epoch 217/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 123.9993 - mae: 7.4688 - val_loss: 200.0230 - val_mae: 10.0008\n",
      "Epoch 218/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 133.9270 - mae: 7.6589 - val_loss: 201.7949 - val_mae: 10.1043\n",
      "Epoch 219/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 129.1035 - mae: 7.6734 - val_loss: 198.9347 - val_mae: 9.8569\n",
      "Epoch 220/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 140.5868 - mae: 7.6420 - val_loss: 192.6513 - val_mae: 9.6124\n",
      "Epoch 221/1000\n",
      "10/10 [==============================] - 63s 6s/step - loss: 115.7991 - mae: 7.0930 - val_loss: 188.0914 - val_mae: 9.6713\n",
      "Epoch 222/1000\n",
      "10/10 [==============================] - 63s 6s/step - loss: 128.5636 - mae: 7.5467 - val_loss: 194.9297 - val_mae: 9.9989\n",
      "Epoch 223/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 126.5140 - mae: 7.5726 - val_loss: 209.6510 - val_mae: 10.4486\n",
      "Epoch 224/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 126.2947 - mae: 7.2594 - val_loss: 189.3145 - val_mae: 9.5930\n",
      "Epoch 225/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 136.0008 - mae: 7.8573 - val_loss: 185.1414 - val_mae: 9.6113\n",
      "Epoch 226/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 140.6324 - mae: 7.7504 - val_loss: 195.4372 - val_mae: 10.0473\n",
      "Epoch 227/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 126.4325 - mae: 7.4260 - val_loss: 193.7166 - val_mae: 9.8816\n",
      "Epoch 228/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 130.4000 - mae: 7.4723 - val_loss: 195.1213 - val_mae: 9.9371\n",
      "Epoch 229/1000\n",
      "10/10 [==============================] - 57s 6s/step - loss: 134.3657 - mae: 7.8462 - val_loss: 196.2428 - val_mae: 10.0724\n",
      "Epoch 230/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 124.2356 - mae: 7.2788 - val_loss: 191.2196 - val_mae: 9.6767\n",
      "Epoch 231/1000\n",
      "10/10 [==============================] - 57s 6s/step - loss: 135.3157 - mae: 7.5986 - val_loss: 197.9428 - val_mae: 9.8480\n",
      "Epoch 232/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 135.1778 - mae: 7.3385 - val_loss: 201.3659 - val_mae: 10.1962\n",
      "Epoch 233/1000\n",
      "10/10 [==============================] - 57s 6s/step - loss: 120.7368 - mae: 7.0780 - val_loss: 200.9117 - val_mae: 10.1642\n",
      "Epoch 234/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 133.9166 - mae: 7.7020 - val_loss: 201.3773 - val_mae: 10.0878\n",
      "Epoch 235/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 126.1242 - mae: 7.2183 - val_loss: 201.2772 - val_mae: 9.9454\n",
      "Epoch 236/1000\n",
      "10/10 [==============================] - 57s 6s/step - loss: 136.9457 - mae: 7.4910 - val_loss: 198.8871 - val_mae: 9.7490\n",
      "Epoch 237/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 135.5913 - mae: 7.5557 - val_loss: 202.3010 - val_mae: 10.0138\n",
      "Epoch 238/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 127.2920 - mae: 7.4401 - val_loss: 199.1662 - val_mae: 9.7991\n",
      "Epoch 239/1000\n",
      "10/10 [==============================] - 57s 6s/step - loss: 114.6859 - mae: 6.8146 - val_loss: 199.7015 - val_mae: 9.8570\n",
      "Epoch 240/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 112.5971 - mae: 6.8844 - val_loss: 205.2802 - val_mae: 9.9944\n",
      "Epoch 241/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 134.6939 - mae: 7.5131 - val_loss: 202.7628 - val_mae: 9.9385\n",
      "Epoch 242/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 126.3083 - mae: 7.5737 - val_loss: 195.6687 - val_mae: 9.7774\n",
      "Epoch 243/1000\n",
      "10/10 [==============================] - 57s 6s/step - loss: 126.9291 - mae: 7.3218 - val_loss: 194.7400 - val_mae: 9.6897\n",
      "Epoch 244/1000\n",
      "10/10 [==============================] - 57s 6s/step - loss: 132.0071 - mae: 7.7359 - val_loss: 198.8423 - val_mae: 9.9208\n",
      "Epoch 245/1000\n",
      "10/10 [==============================] - 58s 6s/step - loss: 126.9916 - mae: 7.4374 - val_loss: 195.0295 - val_mae: 9.7718\n",
      "Epoch 246/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 132.8231 - mae: 7.6428 - val_loss: 196.5916 - val_mae: 9.7899\n",
      "Epoch 247/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 144.4616 - mae: 7.9843 - val_loss: 194.9936 - val_mae: 9.8677\n",
      "Epoch 248/1000\n",
      "10/10 [==============================] - 64s 6s/step - loss: 113.1623 - mae: 6.8109 - val_loss: 193.1803 - val_mae: 9.7612\n",
      "Epoch 249/1000\n",
      "10/10 [==============================] - 63s 6s/step - loss: 124.4093 - mae: 7.1922 - val_loss: 200.5934 - val_mae: 10.0538\n",
      "Epoch 250/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 127.9985 - mae: 7.2476 - val_loss: 195.7860 - val_mae: 9.7629\n",
      "Epoch 251/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 129.4745 - mae: 7.3875 - val_loss: 198.5969 - val_mae: 9.8628\n",
      "Epoch 252/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 126.5891 - mae: 7.3515 - val_loss: 191.0913 - val_mae: 9.6019\n",
      "Epoch 253/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 127.1567 - mae: 7.2132 - val_loss: 193.4078 - val_mae: 9.8106\n",
      "Epoch 254/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 139.5618 - mae: 7.6057 - val_loss: 190.9128 - val_mae: 9.5578\n",
      "Epoch 255/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 124.6403 - mae: 7.2785 - val_loss: 194.6540 - val_mae: 9.7812\n",
      "Epoch 256/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 122.4291 - mae: 7.1838 - val_loss: 209.8744 - val_mae: 10.3169\n",
      "Epoch 257/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 119.4213 - mae: 7.1617 - val_loss: 198.8244 - val_mae: 9.9241\n",
      "Epoch 258/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 133.0411 - mae: 7.5548 - val_loss: 190.9322 - val_mae: 9.6575\n",
      "Epoch 259/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 120.5313 - mae: 7.1120 - val_loss: 206.4180 - val_mae: 10.2231\n",
      "Epoch 260/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 137.5524 - mae: 7.7737 - val_loss: 201.6843 - val_mae: 10.0682\n",
      "Epoch 261/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 129.0577 - mae: 6.9654 - val_loss: 205.3169 - val_mae: 10.1641\n",
      "Epoch 262/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 113.8063 - mae: 6.6836 - val_loss: 206.7659 - val_mae: 10.2196\n",
      "Epoch 263/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 129.1341 - mae: 7.5332 - val_loss: 198.3666 - val_mae: 9.8261\n",
      "Epoch 264/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 115.6050 - mae: 6.7661 - val_loss: 192.6162 - val_mae: 9.6377\n",
      "Epoch 265/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 140.2761 - mae: 7.7143 - val_loss: 196.2267 - val_mae: 9.8452\n",
      "Epoch 266/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 128.6106 - mae: 7.3994 - val_loss: 198.8675 - val_mae: 9.9392\n",
      "Epoch 267/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 138.0997 - mae: 7.6809 - val_loss: 212.4629 - val_mae: 10.4106\n",
      "Epoch 268/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 122.7697 - mae: 6.9765 - val_loss: 198.2487 - val_mae: 9.7680\n",
      "Epoch 269/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 124.9722 - mae: 7.2464 - val_loss: 207.6252 - val_mae: 10.1283\n",
      "Epoch 270/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 122.5084 - mae: 7.1346 - val_loss: 206.3328 - val_mae: 10.0634\n",
      "Epoch 271/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 145.4300 - mae: 7.9576 - val_loss: 201.7332 - val_mae: 9.9300\n",
      "Epoch 272/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 133.4860 - mae: 7.6030 - val_loss: 193.4336 - val_mae: 9.7067\n",
      "Epoch 273/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 131.8580 - mae: 7.3626 - val_loss: 198.6976 - val_mae: 9.7423\n",
      "Epoch 274/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 123.4945 - mae: 7.1565 - val_loss: 199.7803 - val_mae: 9.8606\n",
      "Epoch 275/1000\n",
      "10/10 [==============================] - 63s 6s/step - loss: 126.1210 - mae: 7.3315 - val_loss: 228.0145 - val_mae: 10.9733\n",
      "Epoch 276/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 136.6292 - mae: 7.7408 - val_loss: 203.5285 - val_mae: 10.0752\n",
      "Epoch 277/1000\n",
      "10/10 [==============================] - 63s 6s/step - loss: 133.6892 - mae: 7.5310 - val_loss: 202.9403 - val_mae: 10.0139\n",
      "Epoch 278/1000\n",
      "10/10 [==============================] - 63s 6s/step - loss: 124.6062 - mae: 7.2489 - val_loss: 204.6803 - val_mae: 10.0457\n",
      "Epoch 279/1000\n",
      "10/10 [==============================] - 63s 6s/step - loss: 123.6370 - mae: 7.1893 - val_loss: 206.8809 - val_mae: 10.0403\n",
      "Epoch 280/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 127.0965 - mae: 7.0332 - val_loss: 200.5096 - val_mae: 9.8337\n",
      "Epoch 281/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 104.2471 - mae: 6.3212 - val_loss: 195.9388 - val_mae: 9.7655\n",
      "Epoch 282/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 115.5633 - mae: 7.0951 - val_loss: 194.2423 - val_mae: 9.7043\n",
      "Epoch 283/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 112.3466 - mae: 6.6452 - val_loss: 198.4001 - val_mae: 9.9205\n",
      "Epoch 284/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 129.1025 - mae: 7.1863 - val_loss: 194.0258 - val_mae: 9.8127\n",
      "Epoch 285/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 118.1101 - mae: 6.9132 - val_loss: 199.7719 - val_mae: 9.9882\n",
      "Epoch 286/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 127.1049 - mae: 7.3852 - val_loss: 202.5509 - val_mae: 10.0455\n",
      "Epoch 287/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 125.8477 - mae: 6.9510 - val_loss: 202.8720 - val_mae: 9.8868\n",
      "Epoch 288/1000\n",
      "10/10 [==============================] - 63s 6s/step - loss: 121.1786 - mae: 6.9488 - val_loss: 204.9736 - val_mae: 10.0197\n",
      "Epoch 289/1000\n",
      "10/10 [==============================] - 63s 6s/step - loss: 132.3359 - mae: 7.2743 - val_loss: 201.9654 - val_mae: 10.0183\n",
      "Epoch 290/1000\n",
      "10/10 [==============================] - 63s 6s/step - loss: 118.9244 - mae: 6.9239 - val_loss: 195.9324 - val_mae: 9.9640\n",
      "Epoch 291/1000\n",
      "10/10 [==============================] - 63s 6s/step - loss: 129.4354 - mae: 7.5746 - val_loss: 193.4775 - val_mae: 9.7305\n",
      "Epoch 292/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 130.7902 - mae: 7.3246 - val_loss: 209.4543 - val_mae: 10.2994\n",
      "Epoch 293/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 127.5039 - mae: 7.2971 - val_loss: 228.4482 - val_mae: 10.9716\n",
      "Epoch 294/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 124.4177 - mae: 7.2837 - val_loss: 208.3848 - val_mae: 10.3645\n",
      "Epoch 295/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 132.3225 - mae: 7.3803 - val_loss: 218.5138 - val_mae: 10.6067\n",
      "Epoch 296/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 148.5941 - mae: 7.8186 - val_loss: 218.4521 - val_mae: 10.5891\n",
      "Epoch 297/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 140.4783 - mae: 7.5166 - val_loss: 200.2888 - val_mae: 9.9219\n",
      "Epoch 298/1000\n",
      "10/10 [==============================] - 62s 6s/step - loss: 124.2938 - mae: 7.2356 - val_loss: 212.6591 - val_mae: 10.3005\n",
      "Epoch 299/1000\n",
      "10/10 [==============================] - 61s 6s/step - loss: 129.0417 - mae: 7.2714 - val_loss: 199.2968 - val_mae: 9.7673\n",
      "Epoch 300/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 128.1808 - mae: 7.3395 - val_loss: 216.3909 - val_mae: 10.4708\n",
      "Epoch 301/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 124.6455 - mae: 6.9997 - val_loss: 206.5409 - val_mae: 10.2531\n",
      "Epoch 302/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 118.2185 - mae: 6.9341 - val_loss: 194.0779 - val_mae: 9.9234\n",
      "Epoch 303/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 117.6571 - mae: 6.9696 - val_loss: 198.2551 - val_mae: 9.8374\n",
      "Epoch 304/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 117.5455 - mae: 7.0235 - val_loss: 197.6973 - val_mae: 9.8820\n",
      "Epoch 305/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 111.8580 - mae: 6.5756 - val_loss: 198.5831 - val_mae: 9.9587\n",
      "Epoch 306/1000\n",
      "10/10 [==============================] - 57s 6s/step - loss: 122.0810 - mae: 7.0880 - val_loss: 203.3376 - val_mae: 10.0985\n",
      "Epoch 307/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 113.9394 - mae: 6.8232 - val_loss: 228.2067 - val_mae: 10.9487\n",
      "Epoch 308/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 121.2775 - mae: 7.1922 - val_loss: 213.2848 - val_mae: 10.4416\n",
      "Epoch 309/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 120.1492 - mae: 6.9313 - val_loss: 213.1260 - val_mae: 10.1537\n",
      "Epoch 310/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 122.2659 - mae: 7.0067 - val_loss: 202.1619 - val_mae: 10.0160\n",
      "Epoch 311/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 115.5347 - mae: 7.0130 - val_loss: 198.1726 - val_mae: 9.8642\n",
      "Epoch 312/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 116.8065 - mae: 7.0465 - val_loss: 204.6899 - val_mae: 10.0993\n",
      "Epoch 313/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 116.9235 - mae: 7.0341 - val_loss: 204.2779 - val_mae: 10.0059\n",
      "Epoch 314/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 120.6035 - mae: 6.9637 - val_loss: 204.8706 - val_mae: 10.0738\n",
      "Epoch 315/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 131.0734 - mae: 7.3671 - val_loss: 206.7749 - val_mae: 10.2696\n",
      "Epoch 316/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 118.2310 - mae: 6.9520 - val_loss: 198.7405 - val_mae: 9.8635\n",
      "Epoch 317/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 109.8373 - mae: 6.5088 - val_loss: 197.0585 - val_mae: 9.8157\n",
      "Epoch 318/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 110.0056 - mae: 6.6630 - val_loss: 202.2282 - val_mae: 10.1000\n",
      "Epoch 319/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 117.2145 - mae: 6.9430 - val_loss: 205.6362 - val_mae: 10.3000\n",
      "Epoch 320/1000\n",
      "10/10 [==============================] - 57s 6s/step - loss: 118.5172 - mae: 6.9910 - val_loss: 197.3131 - val_mae: 9.9468\n",
      "Epoch 321/1000\n",
      "10/10 [==============================] - 57s 6s/step - loss: 128.4905 - mae: 7.2545 - val_loss: 194.9681 - val_mae: 9.7138\n",
      "Epoch 322/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 123.3623 - mae: 7.1747 - val_loss: 195.1635 - val_mae: 9.8185\n",
      "Epoch 323/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 117.9518 - mae: 7.0808 - val_loss: 203.3171 - val_mae: 10.2234\n",
      "Epoch 324/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 126.9764 - mae: 7.1877 - val_loss: 208.6105 - val_mae: 10.3565\n",
      "Epoch 325/1000\n",
      "10/10 [==============================] - 56s 6s/step - loss: 125.8511 - mae: 7.2745 - val_loss: 213.2492 - val_mae: 10.4264\n",
      "Epoch 326/1000\n",
      " 4/10 [===========>..................] - ETA: 31s - loss: 127.5738 - mae: 7.0683"
     ],
     "name": "stdout"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-23-73079cd3b6ab>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      7\u001B[0m                     \u001B[0mepochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1000\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m                     \u001B[0mbatch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m64\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 9\u001B[0;31m                     \u001B[0mvalidation_split\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.2\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     10\u001B[0m                     )\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1156\u001B[0m                 _r=1):\n\u001B[1;32m   1157\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1158\u001B[0;31m               \u001B[0mtmp_logs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1159\u001B[0m               \u001B[0;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1160\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    887\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    888\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 889\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    890\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    891\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m_call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    915\u001B[0m       \u001B[0;31m# In this case we have created variables on the first call, so we run the\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    916\u001B[0m       \u001B[0;31m# defunned version which is guaranteed to never create variables.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 917\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# pylint: disable=not-callable\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    918\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    919\u001B[0m       \u001B[0;31m# Release the lock early so that multiple threads can perform the call\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   3022\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[1;32m   3023\u001B[0m     return graph_function._call_flat(\n\u001B[0;32m-> 3024\u001B[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001B[0m\u001B[1;32m   3025\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3026\u001B[0m   \u001B[0;34m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1959\u001B[0m       \u001B[0;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1960\u001B[0m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0;32m-> 1961\u001B[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[0m\u001B[1;32m   1962\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001B[1;32m   1963\u001B[0m         \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    594\u001B[0m               \u001B[0minputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    595\u001B[0m               \u001B[0mattrs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mattrs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 596\u001B[0;31m               ctx=ctx)\n\u001B[0m\u001B[1;32m    597\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    598\u001B[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     58\u001B[0m     \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     59\u001B[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0;32m---> 60\u001B[0;31m                                         inputs, attrs, num_outputs)\n\u001B[0m\u001B[1;32m     61\u001B[0m   \u001B[0;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bn890cNHJ2Ev"
   },
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QJOc7kzlJ2C5"
   },
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UE-9fiM2J1_Y"
   },
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "muwSDszSJ19Z"
   },
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Wvoseom3J16M"
   },
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HZHSt55EJ13o"
   },
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OsEYp8QbJ10y"
   },
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eQWFwZR8QaQ5"
   },
   "source": [],
   "execution_count": null,
   "outputs": []
  }
 ]
}
